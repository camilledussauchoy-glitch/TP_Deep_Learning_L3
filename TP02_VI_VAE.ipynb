{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053a2300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import copy\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae27552",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_path = \"~/datasets\"\n",
    "\n",
    "with_cuda = torch.cuda.is_available()\n",
    "if with_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d869ec",
   "metadata": {},
   "source": [
    "# Reminders on a toy dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ca6367",
   "metadata": {},
   "source": [
    "## Building the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a6350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(height, width):\n",
    "    img = torch.zeros((1, height, width), device = device)\n",
    "    j_pos = torch.randint(2, width - 2, (1,))\n",
    "    for i in range(height):\n",
    "        for j in range(j_pos - 2, j_pos + 2):\n",
    "            img[0, i, j] = 1\n",
    "    cl = torch.randint(0, 4, (1,)).item()\n",
    "    img = transforms.functional.rotate(img, 45*cl)\n",
    "    return img, cl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69de046",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "With the class `torch.utils.data.TensorDataset`, build a dataset generated by the function `generate_image`. Show some samples with matplotlib functiob `imshow`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772ed98e",
   "metadata": {},
   "source": [
    "height, width = 12\n",
    "\n",
    "n = 1000 images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5319b73",
   "metadata": {},
   "source": [
    "dataset = TensorDataset(images, labels)\n",
    "\n",
    "images : Tensor de taille :\n",
    "\n",
    "                        n x nb_de_channels x height x width\n",
    "\n",
    "                          1000x1x12x12\n",
    "\n",
    "labels : Tensor de taille : n\n",
    "--> on utilise pour les entiers un LongTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3103e075",
   "metadata": {},
   "source": [
    "1ere solution possible: liste après tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f38dd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "height = 12\n",
    "width = 12\n",
    "images = []\n",
    "labels = []\n",
    "for i in range(n):\n",
    "  im, cl = generate_image(height,width)\n",
    "  images.append(im)\n",
    "  labels.append(cl)\n",
    "\n",
    "images = torch.stack(images, dim=0)\n",
    "labels = torch.LongTensor(labels)\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea212b1",
   "metadata": {},
   "source": [
    "2e solution possible directement avec tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a1efbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images = torch.zeros((n, 1, height, width), device = device)\n",
    "#ou torch.empty\n",
    "classes = torch.LongTensor(n).to(device)\n",
    "#longtensor : les entiers\n",
    "for i in range(n):\n",
    "  images[i], classes[i] = generate_image(height, width)\n",
    "dataset = torch.utils.data.TensorDataset(images, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a941966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indices = np.random.choice(len(dataset), 10, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(1, 10, figsize=(12, 3))\n",
    "\n",
    "for ax, idx in zip(axes, indices):\n",
    "    img, label = dataset[idx]\n",
    "    ax.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    ax.set_title(label)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e3481b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db92974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "792e5a86",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "Put the dataset into a `DataLoader`. What are the differences between a dataset and a data loader?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86722320",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d72171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4367cc96",
   "metadata": {},
   "source": [
    "What are Conv2d, Linear and MaxPool?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b693643",
   "metadata": {},
   "source": [
    "In a dataset, the elements can be accessed individually given an index (with `[i]`).\n",
    "\n",
    "A data loader is an `Iterable`, which means that its elements can only be accessed through an `Iterator` that traverses the dataset in a way that is provided by the arguments of the data loader (batch size, random/deterministic choice of the data points, etc.). In particular, it can be traversed with a `for` loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a306d5",
   "metadata": {},
   "source": [
    "## Simple NN/training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a593eab",
   "metadata": {},
   "source": [
    "**Question 3**\n",
    "\n",
    "Write a neural network that classifies the data points previously generated. One can use a convolutional and a fully-connected layer.\n",
    "\n",
    "What are the parameters of a convolutional layer? What is their shape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81277a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallCVNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallCVNN, self).__init__()\n",
    "        self.act_function = torch.relu\n",
    "        self.conv = nn.Conv2d(1, 6, 5) #6 : taille de la couche (nb de outchannels, on choisit nous même)\n",
    "        self.fc = nn.Linear(4*4*6,4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.act_function(x)\n",
    "        print(x.shape)\n",
    "        x = torch.nn.functional.max_pool2d(x, 2)\n",
    "        print(x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        print(x.shape)\n",
    "\n",
    "        x = self.fc(x)\n",
    "        x = torch.nn.functional.log_softmax(x, dim=1) #car classification\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c08af5c",
   "metadata": {},
   "source": [
    "Parameters: `conv.bias`, `conv.weight`.\n",
    "\n",
    "`conv.bias`: size `out_channels`\n",
    "\n",
    "`conv.weight`: size `out_channels` * `in_channels` * `kernel_height` * `kernel_width`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec1e461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ef5612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca2ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, nepochs):\n",
    "    #List to store loss to visualize\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    start_epoch = 0\n",
    "\n",
    "    for epoch in range(start_epoch, nepochs):\n",
    "        train_loss = 0.\n",
    "        valid_loss = 0.\n",
    "        correct = 0\n",
    "\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(data_loader):\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "\n",
    "            # update training loss\n",
    "            train_loss += loss.item() * data.size(0)\n",
    "\n",
    "            # accuracy\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "\n",
    "        # calculate average losses\n",
    "        train_loss = train_loss/len(data_loader.dataset)\n",
    "        accuracy = correct/len(data_loader.dataset)*100\n",
    "        train_acc.append(accuracy)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # print losses statistics\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tTraining accuracy: {:.6f}'.format(epoch, train_loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9573a19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac4f2ab5",
   "metadata": {},
   "source": [
    "**Question 4**\n",
    "\n",
    "Choose the loss and train the NN. Why do we choose to minimize the loss instead of maximizing the accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f883787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([104, 6, 8, 8])\n",
      "torch.Size([104, 6, 4, 4])\n",
      "torch.Size([104, 96])\n",
      "Epoch: 0 \tTraining Loss: 1.406862 \tTraining accuracy: 21.900000\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([104, 6, 8, 8])\n",
      "torch.Size([104, 6, 4, 4])\n",
      "torch.Size([104, 96])\n",
      "Epoch: 1 \tTraining Loss: 1.402164 \tTraining accuracy: 22.600000\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([104, 6, 8, 8])\n",
      "torch.Size([104, 6, 4, 4])\n",
      "torch.Size([104, 96])\n",
      "Epoch: 2 \tTraining Loss: 1.399017 \tTraining accuracy: 22.700000\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([104, 6, 8, 8])\n",
      "torch.Size([104, 6, 4, 4])\n",
      "torch.Size([104, 96])\n",
      "Epoch: 3 \tTraining Loss: 1.396752 \tTraining accuracy: 22.700000\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([104, 6, 8, 8])\n",
      "torch.Size([104, 6, 4, 4])\n",
      "torch.Size([104, 96])\n",
      "Epoch: 4 \tTraining Loss: 1.395012 \tTraining accuracy: 23.000000\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([104, 6, 8, 8])\n",
      "torch.Size([104, 6, 4, 4])\n",
      "torch.Size([104, 96])\n",
      "Epoch: 5 \tTraining Loss: 1.393601 \tTraining accuracy: 23.700000\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([104, 6, 8, 8])\n",
      "torch.Size([104, 6, 4, 4])\n",
      "torch.Size([104, 96])\n",
      "Epoch: 6 \tTraining Loss: 1.392412 \tTraining accuracy: 23.600000\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([104, 6, 8, 8])\n",
      "torch.Size([104, 6, 4, 4])\n",
      "torch.Size([104, 96])\n",
      "Epoch: 7 \tTraining Loss: 1.391376 \tTraining accuracy: 24.600000\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([104, 6, 8, 8])\n",
      "torch.Size([104, 6, 4, 4])\n",
      "torch.Size([104, 96])\n",
      "Epoch: 8 \tTraining Loss: 1.390449 \tTraining accuracy: 25.600000\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([128, 6, 8, 8])\n",
      "torch.Size([128, 6, 4, 4])\n",
      "torch.Size([128, 96])\n",
      "torch.Size([104, 6, 8, 8])\n",
      "torch.Size([104, 6, 4, 4])\n",
      "torch.Size([104, 96])\n",
      "Epoch: 9 \tTraining Loss: 1.389605 \tTraining accuracy: 26.200000\n"
     ]
    }
   ],
   "source": [
    "model = SmallCVNN()\n",
    "\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr = .01)\n",
    "\n",
    "train_model(model, criterion, optimizer, nepochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe36bd7",
   "metadata": {},
   "source": [
    "The derivative of the accuracy w.r.t. the parameters of the NN is zero, so the NN cannot be trained with this \"loss\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cfada5",
   "metadata": {},
   "source": [
    "# Variational Auto-Encoders (VAE): MNIST and FashionMNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c64f975",
   "metadata": {},
   "source": [
    "## Building a standard fully-connected VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abb249f",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "Complete the class `VAE_FC`:\n",
    " * build an encoder module;\n",
    " * build a decoder module;\n",
    " * write the method `encode`, which takes an input `x` and returns means and log-variances;\n",
    " * write the method `decode`, which takes a random variable `z` and returns the reconstructed image;\n",
    " * write the method `reparameterization`, taking means and variances and returning normal samples with these means and variances;\n",
    " * write the method `forward`, which takes an input `x` and returns its reconstruction `x_hat`, and the mean/variance of the latent representation.\n",
    "\n",
    "Additionally:\n",
    " * write the method `sample`, which generates new data;\n",
    " * write the method `reconstruct`, which attempts to reconstruct the input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74804dfe",
   "metadata": {},
   "source": [
    "Pourquoi on a besoin de return mean et variance dans le forward : pour la perte : un terme de reconstruction (x_hat) ET un terme qui contient la distance entre la distribution obtenue dans l'espace latent et une distribution a priori (où on a besoin de mean et variance)\n",
    "On a besoin de mean et variance pour train\n",
    "\n",
    "\n",
    "Esp(log(p(x|z))) - KL(q(.|x)|p(.))\n",
    "\n",
    "q: loi normale avec mean et variance données par l'espace latent : N(mu(x), sigmacarré(x))\n",
    "\n",
    "p: prior, normale N(0,sigmacarré0(x))\n",
    "\n",
    "\n",
    "z' = mu(x) + sigma(x)xepsilon\n",
    "-->envoyé dans le décodeur, epsilon suit N(0,1) ==> reparametrisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4afd1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 58.9MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.70MB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.7MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.82MB/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "#mean, std = .2860, .3530\n",
    "\n",
    "# build transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.MNIST(datasets_path, train = True,\n",
    "                              download = True, transform = transform)\n",
    "test_data = datasets.MNIST(datasets_path, train=False,\n",
    "                             download = True, transform = transform)\n",
    "\n",
    "train_size = len(train_data)\n",
    "test_size = len(test_data)\n",
    "\n",
    "# build the data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "# specify the image classes\n",
    "classes = [f\"{i}\" for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cba935c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[784, 392, 300]\n",
      "[392, 300, 200]\n",
      "[200, 300, 392, 784]\n",
      "[200, 300]\n",
      "[300, 392]\n"
     ]
    }
   ],
   "source": [
    "L=[784, 392, 300, 200]\n",
    "print(L[:-1])\n",
    "print(L[1:])\n",
    "rev_L = list(reversed(L))\n",
    "print(rev_L)\n",
    "print(rev_L[:-2])\n",
    "print(rev_L[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48678310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.batchnorm import BatchNorm1d\n",
    "\n",
    "class VAE_FC(nn.Module):\n",
    "    def __init__(self, layers=None, latent_dim=200, leak=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # Si non fourni, on prend une architecture par défaut\n",
    "        if layers is None:\n",
    "            layers = [784, 392, 300, 200]\n",
    "\n",
    "        self.layers = layers\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # -------- Encoder --------\n",
    "        encoder = []\n",
    "        for l_in, l_out in zip(layers[:-1], layers[1:]):\n",
    "            encoder += [nn.Linear(l_in, l_out), nn.LeakyReLU(leak)]\n",
    "        self.encoder = nn.Sequential(*encoder)\n",
    "\n",
    "        # -------- Latent params --------\n",
    "        self.fc_mean   = nn.Linear(layers[-1], latent_dim)\n",
    "        self.fc_logvar = nn.Linear(layers[-1], latent_dim)\n",
    "\n",
    "        # -------- Decoder --------\n",
    "        self.decoder_input = nn.Linear(latent_dim, layers[-1])\n",
    "\n",
    "        rev_layers = list(reversed(layers))  # ex: [200,300,392,784]\n",
    "        decoder = []\n",
    "        for l_in, l_out in zip(rev_layers[:-1], rev_layers[1:]):\n",
    "            decoder += [nn.Linear(l_in, l_out)]\n",
    "            # dernière couche -> sigmoid, sinon activation\n",
    "            if l_out == layers[0]:\n",
    "                decoder += [nn.Sigmoid()]\n",
    "            else:\n",
    "                decoder += [nn.LeakyReLU(leak)]\n",
    "\n",
    "        self.decoder = nn.Sequential(*decoder)\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = x.view(x.size(0),-1)\n",
    "        h = self.encoder(x)                 # (B, layers[-1])\n",
    "        mean = self.fc_mean(h)              # (B, latent_dim)\n",
    "        logvar = self.fc_logvar(h)          # (B, latent_dim)  log(variance)\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterization(self, mean, logvar):\n",
    "      epsilon = torch.randn_like(logvar).to(device)\n",
    "      z = mean + (.5*logvar).exp() * epsilon\n",
    "      return z\n",
    "\n",
    "    def decode(self, x):\n",
    "        x = self.decoder_input(x)\n",
    "        x = self.decoder(x)\n",
    "        return x.view(x.size(0), 1, 28, 28)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, logvar = self.encode(x)\n",
    "        z = self.reparameterization(mean, logvar)\n",
    "        x_hat = self.decode(z)\n",
    "        return x_hat, mean, logvar\n",
    "\n",
    "    def sample(self, num_samples, device=None):\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(num_samples, self.latent_dim, device=device)\n",
    "            return self.decode(z)\n",
    "\n",
    "    def reconstruct(self, x):\n",
    "        with torch.no_grad():\n",
    "            x = x.view(x.size(0), -1)\n",
    "            mean, logvar = self.encode(x)\n",
    "            return self.decode(mean)        # reconstruction \"deterministe\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ff6d77",
   "metadata": {},
   "source": [
    "*encoder:\n",
    "\n",
    "\n",
    "def somme(a,b)\n",
    "\n",
    "  return a+b\n",
    "\n",
    "\n",
    "lst_ab = [2,3]\n",
    "\n",
    "somme(*lst_a,b]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e9a56b",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "Write the function `build_loss_vae`, which builds the loss function for the VAE. The reconstruction loss and the KL loss will be balanced by two parameters `lambda_reconstruct` and `lambda_kl` (by default, they are equal to 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5db09ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cette fonction construit une fonction de perte\n",
    "# on veut construire une fonction dont les paramètres sont fixés dans la fonction qui construit la fonction\n",
    "# cette fonction qui construit les fonction s'appelle une closure --> utile pour construire des fonctions paramétrées\n",
    "\n",
    "from torch.nn.modules import loss\n",
    "\n",
    "def build_loss_vae(lambda_reconstruct = .5, lambda_kl = .5):\n",
    "  def loss_vae(x, x_hat, mean, logvar):\n",
    "    reconstruct_loss = lambda_reconstruct * (x - x_hat).pow(2).sum()\n",
    "    KL_loss = -lambda_kl * torch.sum(logvar - mean.pow(2) - logvar.exp())\n",
    "\n",
    "    return reconstruct_loss + KL_loss\n",
    "  return loss_vae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aac6dea",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfb6efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_vae(data_loader, model, criterion, optimizer, nepochs):\n",
    "    #List to store loss to visualize\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    start_epoch = 0\n",
    "\n",
    "    for epoch in range(start_epoch, nepochs):\n",
    "        train_loss = 0.\n",
    "        valid_loss = 0.\n",
    "        correct = 0\n",
    "\n",
    "        model.train()\n",
    "        for batch_idx, (input_, target) in enumerate(data_loader):\n",
    "            input_ = input_.to(device)\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            # à compléter :\n",
    "            outputs, mean, logvar = model(input_)\n",
    "\n",
    "            # calculate the batch loss\n",
    "            # à compléter :\n",
    "            #input_ = input_.view(input_.size(0), -1)   # (B, 784)\n",
    "            #mean, logvar = model.encode(input_)\n",
    "            loss = criterion(input_, outputs, mean, logvar)\n",
    "            #loss = criterion(input_.view(input_.size(0), -1), outputs, mean, logvar)\n",
    "\n",
    "\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "\n",
    "            # update training loss\n",
    "            train_loss += loss.item() * input_.size(0)\n",
    "\n",
    "        # calculate average losses\n",
    "        train_loss = train_loss/len(data_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # print losses statistics\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "            epoch, train_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea342f2",
   "metadata": {},
   "source": [
    "**Question 3**\n",
    "\n",
    "Train the VAE on MNIST or FashionMNIST. Don't forget to save it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3b294e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tTraining Loss: 16231.607979\n",
      "Epoch: 1 \tTraining Loss: 15982.357638\n",
      "Epoch: 2 \tTraining Loss: 15898.960321\n",
      "Epoch: 3 \tTraining Loss: 15715.149960\n",
      "Epoch: 4 \tTraining Loss: 15592.579556\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = VAE_FC()\n",
    "\n",
    "lambda_reconstruct=.5\n",
    "lambda_kl = .5\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "nepochs = 5\n",
    "\n",
    "criterion = build_loss_vae(lambda_reconstruct = lambda_reconstruct, lambda_kl = lambda_kl)\n",
    "\n",
    "train_model_vae(train_loader, model, criterion, optimizer, nepochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a424db",
   "metadata": {},
   "source": [
    "**Question 4**\n",
    "\n",
    "With the resulting model:\n",
    " * show some generated samples;\n",
    " * check the quality of the reconstruction;\n",
    " * show some interpolations between images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e89a731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch_idx, (input_,target) in enumerate(train_loader):\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    input = input_.to(device)\n",
    "    outputs, mean, logvar = model(input_)\n",
    "\n",
    "indices = np.random.choice(len(outputs), 10, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(1, 10, figsize=(12,3))\n",
    "\n",
    "for ax, idx in zip(axes, indices):\n",
    "  ax.imshow(outputs[idx].squeeze(), cmap=\"gray\")\n",
    "  ax.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff447c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6124f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed9e8a91",
   "metadata": {},
   "source": [
    "## Conditional VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575274ad",
   "metadata": {},
   "source": [
    "**Question 5**\n",
    "\n",
    "Modify the VAE to build a conditional VAE:\n",
    " * the input vectors should be enriched with a one-hot vector coding for the class;\n",
    " * went sent to the decoder, the latent representation should be enriched with a one-hot vector coding for the class.\n",
    "\n",
    "Modify also the function `train_model_vae`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b0f7f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995ec05a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'if' statement on line 20 (2948407004.py, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 22\u001b[0;36m\u001b[0m\n",
      "\u001b[0;31m    else:\u001b[0m\n",
      "\u001b[0m    ^\u001b[0m\n",
      "\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 20\n"
     ]
    }
   ],
   "source": [
    "def train_model_vae(data_loader, model, criterion, optimizer, nepochs, cond = False):\n",
    "    #List to store loss to visualize\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    start_epoch = 0\n",
    "\n",
    "    for epoch in range(start_epoch, nepochs):\n",
    "        train_loss = 0.\n",
    "        valid_loss = 0.\n",
    "        correct = 0\n",
    "\n",
    "        model.train()\n",
    "        for batch_idx, (input_, target) in enumerate(data_loader):\n",
    "            input_ = input_.to(device)\n",
    "            target = target.to(device)\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            if cond:\n",
    "                # ...\n",
    "            else:\n",
    "                # ...\n",
    "\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(input_, output_, mean, logvar)\n",
    "\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "\n",
    "            # update training loss\n",
    "            train_loss += loss.item() * input_.size(0)\n",
    "\n",
    "        # calculate average losses\n",
    "        train_loss = train_loss/len(data_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # print losses statistics\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "            epoch, train_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f0d85f",
   "metadata": {},
   "source": [
    "**Question 6**\n",
    "\n",
    "Train the model.\n",
    "\n",
    "With the resulting model:\n",
    " * show some generated samples;\n",
    " * check the quality of the reconstruction;\n",
    " * show some interpolations between images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9299f480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df55130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf9249e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4819b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b896bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27ffdb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b730eb89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8863bb26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fcf1c79",
   "metadata": {},
   "source": [
    "# Variational inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81490f4",
   "metadata": {},
   "source": [
    "The goal is to build a variational inference (VI) model. We will use the family of independent Gaussian distributions, which means that each parameter $\\theta_k$ of the model will be randomly generated w.r.t. a Gaussian distribution $\\mathcal{N}(\\mu_k, \\sigma_k^2)$. The parameters to be learned are the $(\\mu_1, \\sigma_1^2, \\cdots, \\mu_p, \\sigma_p^2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0821716",
   "metadata": {},
   "source": [
    "To simplify, we will work with a multilayer perceptron. For each pass trhough the model, we will generate randomly the weights and the biases w.r.t. their own Gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a31ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "#mean, std = .2860, .3530\n",
    "\n",
    "# build transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.MNIST(datasets_path, train = True,\n",
    "                              download = True, transform = transform)\n",
    "test_data = datasets.MNIST(datasets_path, train=False,\n",
    "                             download = True, transform = transform)\n",
    "\n",
    "train_size = len(train_data)\n",
    "test_size = len(test_data)\n",
    "\n",
    "# build the data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "# specify the image classes\n",
    "classes = [f\"{i}\" for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005bd12d",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "Build a `Module` named `LinearVI` that is similar to the `Linear` layer, but contains the means and variances of the independent Gaussian distributions generating the weights and the biases:\n",
    "* the log-variances will be stored instead the variances themselves;\n",
    "* the means/log-variances should be implemented both for the weights and the biases;\n",
    "* the `forward` method should be implemented: it is recommended to start with generating Gaussian noise, and then translate and scale it to obtain the weights and biases; one can use the function `F.Linear` to compute the output;\n",
    "* the attributes `weight_prior_logvar` and `bias_prior_logvar` contain the initialization log-variance for the weighs and for the biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d12e2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearVI(nn.Module):\n",
    "    def __init__(self, ...):\n",
    "\n",
    "        ...\n",
    "\n",
    "        self.weight_prior_logvar = np.log(1 / n_in)\n",
    "        self.bias_prior_logvar = np.log(.01)\n",
    "\n",
    "        ...\n",
    "\n",
    "    def forward(self, x):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d09eb3",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "Build a multilayer perceptron `PerceptronVI` made of fully-connected variational layers (`LinearVI`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d93820",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronVI(torch.nn.Module):\n",
    "    def __init__(self, ...):\n",
    "        ...\n",
    "\n",
    "    def forward(self, x):\n",
    "        ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1605c59a",
   "metadata": {},
   "source": [
    "**Question 3**\n",
    "\n",
    "Complete the train function below. The `loss_kl` is defined as:\n",
    "$$\n",
    "L(\\boldsymbol{\\theta}) = \\lambda \\sum_{k = 1}^p \\left[ \\frac{1}{2} \\log\\left(\\frac{\\sigma_{0k}^2}{\\sigma_k^2}\\right) +\\frac{\\sigma_k^2 + \\mu_k^2}{2 \\sigma_{0k}^2} + \\frac{1}{2}\\right] ,\n",
    "$$\n",
    "where $\\sigma_{0k}^2$ is the variance of the prior distribution on $\\theta_k$ (defined for each layer via `weight_prior_logvar` and `bias_prior_logvar`) and $\\lambda$ is the penalty factor `pen_factor`.\n",
    "\n",
    "It is recommended to add new methods to `LinearVI` and `PerceptronVI`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69ed237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_vi(model, criterion, optimizer, nepochs, pen_factor = 1/60000):\n",
    "    #List to store loss to visualize\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    start_epoch = 0\n",
    "\n",
    "    for epoch in range(start_epoch, nepochs):\n",
    "        train_loss = 0.\n",
    "        valid_loss = 0.\n",
    "        correct = 0\n",
    "\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "\n",
    "            # calculate the batch loss\n",
    "            loss_fit = criterion(output, target)\n",
    "            loss_kl = # ... TODO HERE\n",
    "            loss = loss_fit + loss_kl\n",
    "\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "\n",
    "            # update training loss\n",
    "            train_loss += loss.item() * data.size(0)\n",
    "\n",
    "            # accuracy\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "\n",
    "        # calculate average losses\n",
    "        train_loss = train_loss/len(train_loader.dataset)\n",
    "        accuracy = correct/len(train_loader.dataset)*100\n",
    "        train_acc.append(accuracy)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # print losses statistics\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tTraining accuracy: {:.6f}'.format(\n",
    "            epoch, train_loss, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6197adcf",
   "metadata": {},
   "source": [
    "**Question 4**\n",
    "\n",
    "Train the model for various $\\lambda$ and plot the posterior distributions obtained for parameters of different layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d6b491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ae1ede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a32680f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_path = \"~/datasets\"\n",
    "\n",
    "with_cuda = torch.cuda.is_available()\n",
    "if with_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec33cf2e",
   "metadata": {},
   "source": [
    "# Reminders on a toy dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ab8d51",
   "metadata": {},
   "source": [
    "## Building the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "074cc262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(height, width):\n",
    "    img = torch.zeros((1, height, width), device = device)\n",
    "    j_pos = torch.randint(2, width - 2, (1,))\n",
    "    for i in range(height):\n",
    "        for j in range(j_pos - 2, j_pos + 2):\n",
    "            img[0, i, j] = 1\n",
    "    cl = torch.randint(0, 4, (1,)).item()\n",
    "    img = transforms.functional.rotate(img, 45*cl)\n",
    "    return img, cl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e27087",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "With the class `torch.utils.data.TensorDataset`, build a dataset generated by the function `generate_image`. Show some samples with matplotlib functiob `imshow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41da4358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFwAAABZCAYAAACzIkPrAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABGRJREFUeJztnDtLK0EUgE/iJauIDySYGDSYwtpCiFgrWIn+Au1sbMQuRbQRIgoiSsDSToOF+gNEsPEBPrAQgoJIQKKkMImiBpK5zHBdkmu4N5vsnp3dnA8G3E12d/gcZ48zc8bBGGNAoOHEexRBwk2AWjgyJBwZEo4MCUeGhCNDwpEh4ciQcLsIj0aj0NvbC42NjTA4OAjn5+dGPcpSOIwYS4nFYjA5OQmbm5tC9traGuzu7kI8HofOzs5/XlsoFODp6QlaWlrA4XCArHBt2WwWfD4fOJ0a2i0zgGAwyGZmZtTjfD7PfD4fi0Qi/702kUjwBmCZwuurBd27lFwuBxcXFzAyMqKe4y2AH5+cnPz4/tfXF2QyGbVYbfCS/yVqQXfhqVQK8vk8eDyekvP8OJlM/vh+JBKBtrY2tfj9frASWrs906OUUCgE6XRaLYlEAuzML71v6Ha7oaGhAZ6fn0vO82Ov1/vj+4qiiFIv6N7CXS4XDAwMwOHhYUnkwY+Hhob0fpz1YAaws7PDFEVhW1tb7Pb2lk1PT7P29naWTCb/e206nTY98tBSeH21YIhwzsbGBvP7/czlcokw8fT0tKLr7C7ckH98aiGTyYhoxSrwF31ra6t1opR6g4QjQ8KRIeHIkHBkSDgyJBwZEo4MCUeGhCNDwq0+Hm7WGIVVxnyohSNDwpEh4ciQcGRIODIkHBkSjgwJR4aEI0PCkSHhyJBw2YUfHx/D2NiYWPnPl+ru7++XfM7XFc3Pz0NXVxc0NTWJdeF3d3d61rm+hL+/v0N/f7/I4SnH8vIyrK+vi3STs7MzaG5uhtHRUfj8/NSjvtaH1QC/fG9vTz0uFArM6/WylZUV9dzr66tY2Lm9vV3RPe2+tlDXPvzh4UFkORSnm/AxY55YVS7dpFzKCS92Rlfh3ykllaablEs56enpATtjepQSqrOUE12Ff6eUVJpuwuHpJnwqrbjYGV2FBwIBIbY43YT3yTxaoXSTKieR397e4P7+vuRFeX19DR0dHSLlb3Z2FhYXF6Gvr0/8AsLhsIjZJyYmKrq/ZPkB+tdXU0zDGDs6OiobHk1NTamhYTgcZh6PR4SDw8PDLB6PV3z/hM0zkaVLOSn8ybXn1eJ/Mfwlana/zrtFHj0V16XaXHvp1qU4nU7o7u5W43GZXqR/14XWpVgA0+PwekNa4YqiwMLCghRp4XrWRbqXpt2RtoXbFRKODAlHhoQjQ8KRkVZ41IR9DzEmyKUUHovFYG5uTsS+l5eXYtKaT0S/vLwY+lyUCXImIcEa9j3UCyMmyDnStfCcxn0Psahmgrwc0glPadz3EItqJsgtIdzuSCfcrXHfQyyqmSC3hHCXpPse6jZBziRkp4Z9D2shm82yq6srUbia1dVV8fPj46P4fGlpSdTj4OCA3dzcsPHxcRYIBNjHx0fFz5BSeC37HtaC0RPkHBoPR0a6PtzukHBkSDgyJBwZEo4MCUeGhCNDwpEh4ciQcGRIOODyGxx/1xDit9DeAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFwAAABZCAYAAACzIkPrAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABMxJREFUeJztnDtLK0EUx8/GS6KID0RMDBpMYW0hKNYKVqKfQDsbG7FLEUUQIgoiimBpp8FC/QAi2PgAH1iIQUEkIFEsjFF8QDKXGW5CvIkxm8yezG7ODwayz5n89+zZsztzRmOMMSDQsOFVRZDgJYAsHBkSHBkSHBkSHBkSHBkSHBkSHBkS3CqCr6ysQFtbG1RWVkJ3dzccHx8bVZWp0Iz4lhIMBmF4eBhWV1eF2IuLi7C5uQmhUAiamppyHptIJOD+/h5qampA0zRQFS5bLBYDt9sNNpsOu2UG0NXVxcbGxlLL8Xicud1uFggEfj02HA5zAzBN4e3Vwx/ZV/7r6wtOTk7A5/Ol1nEL6Ovrg4ODg4z9Pz8/RUkzAF31RaPRH7fV1dWB0fA7UQ/SBX96eoJ4PA5Op/Pber58dXWVsX8gEIDp6emC66utrYVSotftlTxK8fl8wkqTJRwO59yf3wHpJd99VUG6hTc2NkJFRQU8PDx8W8+XXS5Xxv4Oh0OUckG6hdvtdujs7ITd3d1vkQdf7unpkV2d+WAGsLGxwRwOB1tbW2OXl5dsdHSU1dfXs0gk8uux0Wg0IxIwAllRCm+vrnoN+TeMseXlZebxeJjdbhdh4uHhYV7HWV1wQ158iuHl5SUjnDOiibJeqviDXk+kVPIopdyQHqUYgZZmjbKs/f/zYH1GIAtHhgRHxhQuJdetb4SLMdK9kIUjQ4IjQ4IjYzofbvaQkSwcGRIcGdO7FLOFjGThyJDgyJDgyFhacE3TUkUWyU7pXMMzylZwFSHBkSHBkbFUHF6KGF0vZOHIkODIlI1LkeVi6NXe6i5lf38fBgYGxMh/frW3t7czLGVychKam5uhqqpKjAu/vr6W2ebyEvzt7Q06OjpEDk825ubmYGlpSaSbHB0dQXV1NfT398PHx4eM9pqfYsfnbW1tpZYTiQRzuVxsfn4+te75+VkM7FxfXy94bCF2yfY/ZY0tlBql3N7eQiQSEW4kCR8nyBOrsqWbcHi6CR9PmF6sjFTBudicbOkmyW3ZUk74RUmW1tZWsDKmSznB/sooe1CQVMGTKSX5pptweLoJH+6bXqyMVMG9Xq8QNj3dhPtkHq1QukmBb5qvr69wc3Pz7UF5fn4ODQ0N4PF4YHx8HGZmZqC9vV1cAL/fL2L2oaGhvM6vWH6A/PbqimkYY3t7e1nDo5GRkVRo6Pf7mdPpFOFgb28vC4VCeZ8/bPFMZOVSThL/cu15s/gdwx+ipfbr3C3y6Cm9LYXm2iv38cpms0FLS0sqHlfpQfp/WwpJLS95WFhukODIKCu4w+GAqakpJdLCZbZFuYem1VHWwq0KCY4MCY4MCY4MCY6MsoKvlGDeQ4wOciUFDwaDMDExIWLf09NT0WnNO6IfHx8NrRelg5wpSFcR8x7KwogOco5yFv71b97D9I7oXPMeYlFIB3k2lBP8Kce8hz91RGNQSAe5KQS3OsoJ3qhz3kMsCukgN4XgdkXnPZTWQc4UZKOIeQ+LIRaLsbOzM1G4NAsLC+L33d2d2D47OyvasbOzwy4uLtjg4CDzer3s/f097zqUFLyYeQ+LwegOcg59D0dGOR9udUhwZEhwZEhwZEhwZEhwZEhwZEhwZEhwZEhwZEhwwOUvlm2YF5ryXuwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFwAAABZCAYAAACzIkPrAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABMhJREFUeJztnDtLK0EUx0/iJVHEByImBg2msLYQFGsFK9FPoJ2NjdiliCIIEQURRbC002ChfgARbHyADyzEoCASkCgWrlF8QDKXGW7C5pqbm01mT2bX84MBd7OP8Z+zZ072zBkHY4wBgYYT71YECV4GyMKRIcGRIcGRIcGRIcGRIcGRIcGRIcHtIvjKygq0tbVBZWUldHd3w/HxsVm3shQOM96lRCIRGB4ehtXVVSH24uIibG5uQjQahaamprznplIpuL+/h5qaGnA4HKAqXLZEIgE+nw+cTgN2y0ygq6uLjY2NZbaTySTz+XwsHA7/99xYLMYNwDKN99cIv2R/819fX3BycgLBYDCzj1tAX18fHBwcfDv+8/NTNJ0BgBlomlbwsXV1dQUfy59EI0gX/OnpCZLJJHg8nqz9fPvq6urb8eFwGKanp8FsamtrTbmuUbdX9iglGAwK60u3WCwm7dr8aUm3Ys+T/cRJt/DGxkaoqKiAh4eHrP182+v1fjve7XaL9lOQbuEulws6Ozthd3c3K/Lg2z09PbJvZz2YCWxsbDC3283W1tbY5eUlGx0dZfX19Swej//3XE3Tio4YzCLfPXl/DV3LrE4uLy8zv9/PXC6XCBMPDw8LOs/ugpvyw6cUXl5eDIVlesz6V/JFInygNxIBlT1K+WlIj1KwYSZYtZmvFMjCkSHBkbGcS2FlGBhlQhaODAmODAmOjCV8OLNY6JcPsnBkSHBklBVc0zSpCQDuQvStXCgruF0hwZEhwZGxRFhYLCpOJCILR4YER4YER8ZWPtyhoM/+G7JwZEhwZJR1KXW6qRL5ft5bwY3oIQtXXfD9/X0YGBgQM/+5dW1vb2d9zq1xcnISmpuboaqqSswLv76+ltnnnyX429sbdHR0iBqeXMzNzcHS0pIoNzk6OoLq6mro7++Hj48PGf21PqXOudva2spsp1Ip5vV62fz8fGbf8/OzmNi5vr5u+tzCcjSjcwul+vDb21uIx+PCjegHP15YlavchMPLTfh8Qn2zM1IF52JzcpWbpD/LVXLCv5R0a21tBTtj65IT2wueLikptNyEw8tN+HRffbMzUgUPBAJCWH25CffJPFqhcpMif2m+vr7Czc1N1kB5fn4ODQ0N4Pf7YXx8HGZmZqC9vV18AaFQSMTsQ0NDBV1fsfoA+f01FNMwxvb29nKGRyMjI5nQMBQKMY/HI8LB3t5eFo1GC75+zOaVyMqVnKT+1NrzbvEnhg+i5fbr3C3y6Enfl2Jr7ZV7eeV0OqGlpSUTj6s0kP7dl2JqkcoeFv40SHBklBXc7XbD1NSUEmXhMvui3KBpd5S1cLtCgiNDgiNDgiNDgiOjrOArZVj3ECNBrqTgkUgEJiYmROx7enoqktY8Ef34+GjqfVES5ExBukpY91AWZiTIOcpZ+NefdQ/1ieh86x5iUUyCPBfKCf6UZ93DfyWiMSgmQW4Jwe2OcoI3Glz3EItiEuSWENyl6LqH0hLkTEE2Slj3sBQSiQQ7OzsTjUuzsLAg/r67uxOfz87Oin7s7Oywi4sLNjg4yAKBAHt/fy/4HkoKXsq6h6VgdoKcQ+/DkVHOh9sdEhwZEhwZEhwZEhwZEhwZEhwZEhwZEhwZEhwZEhxw+Q2fhYBEkVYmyQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFwAAABZCAYAAACzIkPrAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABItJREFUeJztnM1LMkEYwB/txS2iD0LSpCQPnTsEReeCTlF/Qd26dIluHiyCwCiIKIKO3Uo6VH9ABF36gD7oEElBhBAWHjKLStB5mSFFX33NXXcfx/X5wYC7urvDb8fZR2eesTDGGBBoWPEuRZDwMkAtHBkSjgwJR4aEI0PCkSHhyJBwZEi4WYSvr69DZ2cn1NbWQl9fH5ydnRl1qYrCYsR/KYFAAMbGxmBjY0PIXllZgZ2dHQgGg9Da2lrw2GQyCU9PT9DQ0AAWiwVkhWuLxWLgcrnAalXRbpkB9Pb2ssnJyfR2IpFgLpeL+f3+X48NhUK8AVRM4fVVwx+973w8Hofz83Pwer3pfbwFDA4OwvHxcc7nv7+/RcloAAXPH41GNdWrqakJjIB/E9Wgu/BIJAKJRAIcDkfWfr59e3ub83m/3w9zc3NFn7+xsRFkQm23V/Yoxev1ilabKqFQCMyM7i3cbrdDTU0NPD8/Z+3n206nM+fziqKIUi3o3sJtNhv09PTAwcFBVuTBt/v7+/W+XOXBDGB7e5spisI2NzfZzc0Nm5iYYM3NzSwcDv96bDQaLRgVaMWoKIXXV1U9mEGsra0xt9vNbDabCBNPTk6KOs7swg354VMKb29vBUM4rdU16kcUf9CriZzKHqVUGyQcGRKODAlHhoQjQ8KRIeHIkHBkSDgyJBwZEo4MCUeGhCNDwpEh4ciQcGRIODIkHBkSjgwJR4aEI0PCkSHhyJBw2YUfHR3B8PCwmPnPJ9fs7e3lTNSZmZmBtrY2qKurE/PC7+7u9KxzdQn/+PiA7u5ukcOTj8XFRVhdXRXpJqenp1BfXw9DQ0Pw9fWlR30rH82T9X7m6+3u7qa3k8kkczqdbGlpKb3v9fVVTOzc2toq6pxmn1uoax/+8PAA4XBYdCMp+DxBnliVL92Ew9NN+HzCzGJmdBXOZXPypZuk3suXcsJvSqp0dHSAmSl7lOKtspQTXYWnUkqKTTfh8HQTPt03s5gZXYV7PB4hNjPdhPfJPFqhdBONSVXv7+9wf3+f9aC8urqClpYWcLvdMDU1BfPz89DV1SVugM/nEzH76OhoUef/bcK9bA9V1QkCasOrw8PDvOHR+Ph4OjT0+XzM4XCIcHBgYIAFg8Gizx8yeSaydCknyZ9ce14t/o3hD9Fy9+v8W8Wjp8y6aM211z1Ps1SsViu0t7enuw6ZHqT/1kVLOnnZw8Jqg4QjI61wRVFgdnZWirRwPesi3UPT7Ejbws0KCUeGhCNDwpEh4chIK3y9DOseYgyQSyk8EAjA9PS0iH0vLi7EoDUfiH55eTH0uigD5ExCektY91AvjBgg50jXwuM/6x5mDkQXWvcQCy0D5PmQTnikwLqH/xuIxkDLAHlFCDc70gm3q1z3EAstA+QVIdwm6bqHug2QMwnZLmHdw1KIxWLs8vJSFK5meXlZvH58fBTvLywsiHrs7++z6+trNjIywjweD/v8/Cz6GlIKL2Xdw1IweoCcQ/+HIyNdH252SDgyJBwZEo4MCUeGhCNDwpEh4ciQcGRIODIkHHD5C8+XUx1gaq4VAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFwAAABZCAYAAACzIkPrAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABM1JREFUeJztnDtLK0EUx0/iJVHEByImBg2msLYQFGsFK9FPoJ2NjdiliCIIEQURRbC002ChfgARbHyADyzEoCASkCgWrlF8QDKXGTRsNDc3m8yezK7nBwPuc8b/nj1zsjNnHIwxBgQaTryqCBK8BJCFI0OCI0OCI0OCI0OCI0OCI0OCI0OC20XwpaUlaGlpgfLycujs7ITDw0OzqrIUDjO+pUQiERgcHITl5WUh9vz8PKyvr0M0GoWGhoac16ZSKbi9vYWqqipwOBygKly2RCIBPp8PnE4DdstMoKOjg42MjKS3k8kk8/l8LBwO//faWCzGDcAyhbfXCH9kP/mPjw84OjqCYDCY3sctoKenB/b29n6c//7+LorOAAADTdP+eaympibv+/A30QjSBX94eIBkMgkejydjP9++uLj4cX44HIbJyUnAprq6Wsp9jLq9kkcpwWBQWNtXicViptTD3xx9kXWuUaRbeH19PZSVlcHd3V3Gfr7t9Xp/nO92u0X5LUi3cJfLBe3t7bC9vZ0RefDtrq4u2dVZD2YCa2trzO12s5WVFXZ+fs6Gh4dZbW0ti8fj/71W0zRpEYQZfK+Dt9fQ9aa0ijG2uLjI/H4/c7lcIkzc39/P6zq7C27KD59ieHp6MhSW5cKMf+17VMI7eiMRT8mjlN+G9CillDCTXlaZnxjIwpEhwZGxvEthCB2jTMjCkSHBkSHBkbGcD2cWCP1yQRaODAmOjCVcCrNY6JcLsnBkSHBkSHBklBVc0zSpg7jcZ+tLqVBWcLtCgiNDgiNjiTi8UFScDEoWjgwJjoyyLqVGN1Ui39BQRRfyHbJw1QXf3d2Fvr4+MfOfW9Tm5mbGcW6N4+Pj0NjYCBUVFWJe+OXlpcw2/y7BX15eoK2tTeTwZGNmZgYWFhZEusnBwQFUVlZCb28vvL29yWiv9Sl2nt3GxkZ6O5VKMa/Xy2ZnZ9P7Hh8fxcTO1dVVKXMLs7WhlMXo3EKpPvz6+hri8bhwI/rOjydWZUs34fB0Ez6fUF/sjFTBudicbOkmX8eypZzwh/JVmpubwc5YLuXEochXPyUE/0opyTfdhMPTTfh0X32xM1IFDwQCQlh9ugn3yTxaoXSTAn9pPj8/w9XVVUZHeXp6CnV1deD3+2F0dBSmpqagtbVVPIBQKCRi9oGBgbzur1h+gPz2GoppGGM7OztZw6OhoaF0aBgKhZjH4xHhYHd3N4tGo3nfP2bzTGTlUk5Sn7n2vFn8jeGdaKn9OneLPHrSt6XQXHvlPl45nU5oampKx+MqdaTf21JILlLJw8LfBgmOjLKCu91umJiYUCItXGZblOs07Y6yFm5XSHBkSHBkSHBkSHBklBV8qQTrHmIMkCspeCQSgbGxMRH7Hh8fi0FrPhB9f39var0oA+RMQTqKWPdQFmYMkHOUs/CPz3UP9QPRudY9xKKQAfJsKCf4Q451D/81EI1BIQPklhDc7igneL3BdQ+xKGSA3BKCuxRd91DaADlTkLUi1j0shkQiwU5OTkTh0szNzYm/b25uxPHp6WnRjq2tLXZ2dsb6+/tZIBBgr6+vedehpODFrHtYDGYPkHPoezgyyvlwu0OCI0OCI0OCI0OCI0OCI0OCI0OCI0OCI0OCI0OCAy5/AfuEjEQXMMKYAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFwAAABZCAYAAACzIkPrAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABIpJREFUeJztnMtLckEUwI/24S2iBxFpUpKL1i0Co3VBq6i/oHZt2kQ7FxZBYBREFEHLdiUtqj8ggjY9oActIimIEMKiRWbRA3Q+ZkixLz/zXucex+v5wUD3eh/Tz3Hu0ZkzNsYYAwINO96tCBJeBKiFI0PCkSHhyJBwZEg4MiQcGRKODAm3ivDl5WVoa2uDyspK6OrqgqOjI7NuVVLYzPgtJRQKwdDQEKysrAjZCwsLsLGxAeFwGJqamnKem0wm4e7uDmpqasBms4GqcG3xeBzcbjfY7TraLTMBn8/HRkdH09uJRIK53W4WDAZ/PTcSifAGUDKF11cPf2S/85+fn3B8fAx+vz+9j7eA3t5e2N/f/3H8x8eHKBkNQFpdYrGYofPq6uryPpZ/EvUgXfjj4yMkEglwOp3f9vPty8vLH8cHg0GYmpoCM6itrQWz0dvtFT1K8fv9oiWmSiQSASsjvYU3NjZCRUUF3N/ff9vPt10u14/jNU0TpVyQ3sIdDgd0dnbCzs7Ot8iDb3d3d8u+XenBTGB9fZ1pmsZWV1fZxcUFGxkZYfX19Swajf56biwWkxZBGEXPPXh9dV2bmcTS0hLzeDzM4XCIMPHg4CCv86wu3JQvPoXw/PysKyzLhdF/TU/kwR/0eqKhokcp5QYJR4aEI0PCkSHhyJBwZEg4MiQcGRKODAlHhoQjQ8KRIeHIkHBkSDgyJBwZEo4MCUeGhCNDwpEh4ciQcGRIODIkXHXhe3t70N/fL2b+8wkzW1tbPybfTExMQHNzM1RVVYl54VdXVzLrXF7CX19foaOjQ+TwZGN2dhYWFxdFusnh4SFUV1dDX18fvL+/y6hv6WN4At7XHLzNzc30djKZZC6Xi83NzaX3PT09iYmda2treV3T6nMLpfbhNzc3EI1GRTeSgs8T5IlV2dJNODzdhM8nzCxWRqpwLpuTLd0k9Vq2lBP+pqRKa2srWJmiRyn+Mks5kSo8lVKSb7oJh6eb8Om+mcXKSBXu9XqF2Mx0E94n82iF0k0MJlW9vLzA9fX1twfl2dkZNDQ0gMfjgbGxMZienob29nbxBgQCARGzDw4O5nV9mfkBGA9g3fXVGzLt7u5mDY+Gh4fToWEgEGBOp1OEgz09PSwcDud9/YjFM5GVSzlJfuXa82rxTwx/iBa7X+efFB49ZdbFaK699DzNQrHb7dDS0pLuDlR6kP5bFyO5SEUPC8sNEo6MssI1TYPJyUkl0sJl1kW5h6bVUbaFWxUSjgwJR4aEI0PCkVFW+HIR1j3EGCBXUngoFILx8XER+56cnIhBaz4Q/fDwYOp9UQbImYL4Clj3UBZmDJBzlGvhn1/rHmYOROda9xALIwPk2VBO+GOOdQ//NxCNgZEB8pIQbnWUE96oc91DLIwMkJeEcIei6x5KGyBnCrJewLqHhRCPx9np6akoXM38/Lz4+/b2Vrw+MzMj6rG9vc3Oz8/ZwMAA83q97O3tLe97KCm8kHUPC8HsAXIO/R6OjHJ9uNUh4ciQcGRIODIkHBkSjgwJR4aEI0PCkSHhyJBwwOUvr+ZTHQ1MrRsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFwAAABZCAYAAACzIkPrAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABKZJREFUeJztnDtLK0EUgE/iJauIDySYGDSYwtpCUKwVrER/gXY2NmJnEW2EiIKIIljaabBQf4AINj7ABxZCUBAJSBQLkyg+IJnLDNcl0eDNJrNnZzfngwF33XWHz9nZsztzxsUYY0Cg4ca7FEHCLYBaODIkHBkSjgwJR4aEI0PCkSHhyJBwpwhfXV2F9vZ2qK6uhp6eHjg5OTHrUrbCZca3lGg0CiMjI7C2tiZkLy0twdbWFsRiMWhubv713Gw2C/f391BXVwculwtUhWtLp9MQCATA7TbQbpkJdHd3s/HxcX07k8mwQCDAIpHIf8+Nx+O8Adim8PoaQXqX8vn5Caenp9Df36/v4y2Abx8eHv44/uPjA1KplF7s9vGS34lGkC786ekJMpkM+Hy+vP18O5FI/Dg+EolAQ0ODXoLBINgJo92e5VHK1NQUJJNJvcTjcaurJO6y3CKTP1L/GgB4vV6oqqqCh4eHvP182+/3/zhe0zRRKgXpLdzj8UBXVxfs7e3lRR58u7e3V/bl7Aczgc3NTaZpGltfX2dXV1dsbGyMNTY2skQi8d9zk8mkJdFGsXw/j9fXCKYI56ysrLBgMMg8Ho8IE4+Ojoo6z+nCTXnxKYdUKiWiFWyK1fA9KuEP+vr6evtEKZVGxQpnJYZ+X8fzll0KFSvcKkg4MtJffFSFKRIbUAtHhoQjQ8KRcXQfzkzot8sdhaIWjgwJR8ZRXQozKfSTOZhNLRwZEo4MCUfG9n04UzD0+w1q4ciQcGRIODK268OZDWLt36AWjgwJR8YWXQqzWej3G9TCVRd+cHAAg4ODYuY/byU7Ozs/WuP09DS0tLRATU2NmBd+fX0ts86VJfz19RU6OztFDk8h5ufnYXl5WaSbHB8fQ21tLQwMDMD7+7uM+tofQxPjCsyz297e1rez2Szz+/1sYWFB3/f8/Cwmdm5sbEiZW1hOXc0oRucWSu3Db29vRZZDbroJnyfIE6sKpZsUSjnhxclIFf6VUlJsukmhlJO2tjZwMrZLOXG5XHml2GMdKfwrpaTYdBMOTzfh031zi5ORKjwUCgmxuekmvE/m0Qqlm5T4pvny8gI3Nzd5D8qLiwtoamoSKX8TExMwOzsLHR0d4h8QDodFzD48PGzKW6XVD1nDb8FGw6v9/f2C4dHo6KgeGobDYebz+UQ42NfXx2KxWNF/P+7wTGTlUk6y/3LtebX4HcMfolb36/wu4tFTbl1KzbVX7uOV2+2G1tZWvatQ6UH6vS6l5CJZHhZWGiQcGWWFa5oGMzMzSqSFy6yLcg9Np6NsC3cqJBwZEo4MCUeGhCOjrPBVC9Y9xBggV1J4NBqFyclJEfuenZ2JQWs+EP34+GjqdVEGyJmCdJex7qEszBgg5yjXwj8NrnuIRSkD5IVQTviTwXUPsShlgNwWwp2OcsK9Btc9xKKUAXJbCPcouu6htAFypiCbZax7WA7pdJqdn5+LwtUsLi6Kn+/u7sTv5+bmRD12d3fZ5eUlGxoaYqFQiL29vRV9DSWFl7PuYTmYPUDOoe/hyCjXhzsdEo4MCUeGhCNDwpEh4ciQcGRIODIkHBkSjgwJB1z+AlHHb2B7HaVhAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFwAAABZCAYAAACzIkPrAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABGpJREFUeJztnM1LKlEUwI/2cIooIyRNSnLRukVgtC5oFfUX1K5Nm2jnwtoERkFEIbRsl9Ki+gMiaNMH9EGLQAoihLBwkVpUgt7HvbwGfcl7js4c74znBxeacT4uv653jnPvuTbGGAMCDTverQgSXgeohSNDwpEh4ciQcGRIODIkHBkSjgwJt4rwSCQCfX190NzcDENDQ3B+fm7UrUyFzYh3KbFYDKampmBra0vIXl9fh93dXYjH49DV1fXPcwuFAjw9PUFbWxvYbDaQFa4tm82C1+sFu11Du2UGEAgE2OzsrLqdz+eZ1+tl4XD4v+cmEgneAExTeH21oHuXksvl4OLiAkZHR9V9vAXw7ZOTkx/Hf319QSaTUYvZXl7yb6IWdBeeSqUgn8+D2+0u2c+3k8nkj+PD4TA4nU61+Hw+MBNau726RynBYBDS6bRaEokEWJlfel/Q5XJBU1MTPD8/l+zn2x6P58fxiqKI0ijo3sIdDgcMDg7C4eFhSeTBt4eHh/W+nflgBhCNRpmiKGx7e5vd3t6ymZkZ1tHRwZLJ5H/PTafTdY88tBReXy0YIpyzubnJfD4fczgcIkw8PT2t6DyrCzfkh08tZDIZEa2YBf6gb29vN0+U0miQcGRIODIk3Ow/fOr1MDLLw51aODIkHBkSjgwJR4aEI0PCkSHhyJBwZEg4MiQcGRKODAlHhoQjQ8KRkfb1rNNE45paoBaODAlHhoQjQ8JlF358fAzj4+Ni5j+fqru/v1/yOZ9XtLCwAN3d3dDS0iLmhd/d3elZ58YS/v7+DgMDAyKHpxwrKyuwsbEh0k3Ozs6gtbUVxsbG4PPzU4/6mh9WA/z0vb09dbtQKDCPx8NWV1fVfa+vr2Ji587OTkXXtPrcQl378IeHB5HlUJxuwuNpnlhVLt2kXMoJL1ZGV+HfKSWVppuUSznp7e0FK1P3KCXYYCknugr/TimpNN2Ew9NN+Ayr4mJldBXu9/uF2OJ0E94n82iF0k2qfHn19vYG9/f3JQ/K6+tr6OzsFCl/c3NzsLS0BP39/eIfEAqFRMw+OTlZ0fUlyw/Qv76aYhrG2NHRUdnwaHp6Wg0NQ6EQc7vdIhwcGRlh8Xi84usnLJ6JLF3KSeFPrj2vFv/G8Idovft13i3y6Km4LtXm2kv3Ptxut0NPT48aj8v0IP27LjRd2QTUPQ5vNKQVrigKLC4uSpEWrmddpHtoWh1pW7hVIeHIkHBkSDgyJBwZaYVH6rDuIcYAuZTCY7EYzM/Pi9j38vJSDFrzgeiXlxdD74syQM4kJFDDuod6YcQAOUe6Fp7TuO4hFtUMkJdDOuEpjeseYlHNALkphFsd6YS7NK57iEU1A+SmEO6QdN1D3QbImYREa1j3sBay2Sy7uroShatZW1sTfz8+PorPl5eXRT0ODg7Yzc0Nm5iYYH6/n318fFR8DymF17LuYS0YPUDOoffhyEjXh1sdEo4MCUeGhCNDwpEh4ciQcGRIODIkHBkSjgwJB1x+A1ey1z8xeKZIAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFwAAABZCAYAAACzIkPrAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABJBJREFUeJztnM1LKlEUwI/2cIrog4g0KclF6xZB0bqgVdRfULs2baKdC4sgMAoiiqBlu5IW1R8QQZs+oA9aRFIQIYRFi8yiD9D7OJen6MvXc3Q8cx3PDy46M45z+c2dmaP3nmsTQghgyLDTHYph4SbALZwYFk4MCyeGhRPDwolh4cSwcGJYuFWEr6ysQFtbG1RWVkJ3dzccHx8X61Alha0Y/6UEg0EYHh6G1dVVKXtxcRE2NzchFApBU1PTj/smEgm4v7+HmpoasNlsoCqoLRaLgdvtBrtdR7sVRaCrq0uMjY2lluPxuHC73SIQCPx333A4jA2gZArWVw+/jD7zX19fcHJyAj6fL7UOW0BfXx8cHBx8+/zn56csaQ1AvobDYaitrdV17Lq6OqAGr0Q9GC786ekJ4vE4OJ3OjPW4fHV19e3zgUAApqenv61H2XqFm4He257pUYrP54NoNJoq2LKtjOEtvLGxESoqKuDh4SFjPS67XK5vn9c0TZZywfAW7nA4oLOzE3Z3dzMiD1zu6ekx+nClhygCGxsbQtM0sba2Ji4vL8Xo6Kior68XkUjkv/tGo1H59MdXvZgRpeitZ1GEI8vLy8Lj8QiHwyHDxMPDw5z2s7rwovzwKYSXlxcZ3uEDVG+UYsYPJb31ND1KKTdYODEsnBgWTgwLJ4aFE8PCiWHhxLBwYlg4MSycGBZODAsnhoUTw8KJYeHEsHBiWDgxLJwYFk4MCyeGhRPDwolh4aoL39/fh4GBATnyHwfebG9vZ2zHcUWTk5PQ3NwMVVVVclz49fW1kXUuL+Fvb2/Q0dEhc3iyMTc3B0tLSzLd5OjoCKqrq6G/vx8+Pj6MqG/po3sA319j+ba2tlLLiURCuFwuMT8/n1r3/PwsB3aur6/n9J1WH1to6D389vYWIpGIvI0kwXGCmFiVLd0EwXQTHE+YXqyMocJRNpIt3SS5LVvKCZ6UZGltbQUrY3qU4iuzlBNDhSdTSnJNN0Ew3SSZQFUqiVTKCPd6vVJseroJ3pMxWuF0kzyTql5fX+Hm5ibjQXl+fg4NDQ3g8XhgfHwcZmZmoL29XZ4Av98vY/ahoaGcvj+ZH1AqD0/d+Qx6Q6+9vb2s4dHIyEgqNPT7/cLpdMpwsLe3V4RCoZy/P2zxTGTlUk4Sf3LtsVp4xeSTkWw0eLVh9JRel3xz7Q3P0ywUu90OLS0tqVuKSg/Sv+uST6q56WFhucHCiVFWuKZpMDU1pURauJF1Ue6haXWUbeFWhYUTw8KJYeHEsHBilBW+YsK8hxQd5EoKDwaDMDExIWPf09NT2WmNHdGPj49FPS5JB7lQkK4C5j00imJ0kCPKtfCvP/MepndE/zTvIRX5dJBnQznhTz/Me/ivjmgK8ukgLwnhVkc54Y065z2kIp8O8pIQ7lB03kPDOsiFgmwUMO9hIcRiMXF2diYLqllYWJDv7+7u5PbZ2VlZj52dHXFxcSEGBweF1+sV7+/vOR9DSeGFzHtYCMXuIEf4/3BilLuHWx0WTgwLJ4aFE8PCiWHhxLBwYlg4MSycGBZODAsHWn4DQ11J0qCRImUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFwAAABZCAYAAACzIkPrAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABL5JREFUeJztnDtLK0EUx0/iJVHEByImBg2msLYQFGsFK9FPoJ2NjdiliCIIEQURRbC002ChfgARbHyADyzEoCASkCgWxig+IJnLDCYkmpub3cyezG7ODwbczW5m/Ofs2bN75oyNMcaAQMOO1xVBgpcAsnBkSHBkSHBkSHBkSHBkSHBkSHBkSHCrCL6ysgJtbW1QWVkJ3d3dcHx8bFRXpsJmxLuUUCgEw8PDsLq6KsReXFyEzc1NCIfD0NTUlPfcZDIJ9/f3UFNTAzabDVSFyxaPx8Hj8YDdrsFumQF0dXWxsbGx9HYikWAej4cFg8H/nhuJRLgBmKbx8Wrhj+xf/uvrC05OTsDv96f3cQvo6+uDg4ODX8d/fn6KlmEAuvuOxWIgg7q6uoKP5VeiFqQL/vT0BIlEAlwuV9Z+vn11dfXr+GAwCNPT01L6rq2tBWy0ur2SRyl+v19YZqpFIhFN5/MrItXMgHQLb2xshIqKCnh4eMjaz7fdbvev451Op2jlgnQLdzgc0NnZCbu7u1mRB9/u6emR3Z35YAawsbHBnE4nW1tbY5eXl2x0dJTV19ezaDT633NjsVjeqMAo9EYpfLya+jHqH1heXmZer5c5HA4RJh4eHhZ0ntUFN+TBpxheXl7yhmVGDVfvQxa/0WuJjkoepZQb0qMUI2AGWHWpXhuQhSNDgiOjrOCxWEzqEyR3IZmtVCgruFUhwZEhwZExRVioFxUzRmThyJDgyFjKpdgUdCE/IQtHhgRHhgRHxvQ+3GYCv50JWTgyJDgyJDgypvPhNpP57J+QhSNDgiOjrEup0zCD1UyQhasu+P7+PgwMDIiZ//wGtr29nfU5z0FOTk5Cc3MzVFVViXnh19fXMsdcXoK/vb1BR0eHqOHJxdzcHCwtLYlyk6OjI6iurob+/n74+PiQMV7zU+x8vK2trfR2Mplkbrebzc/Pp/c9Pz+LiZ3r6+tS5haq1rTOLZTqw29vbyEajQo3knnz44VVucpNOLzchM8nzGxWRqrgXGxOrnKT1Ge5Sk74j5Jqra2tYGVMX3JS1oKnSkoKLTfh8HITPt03s1kZqYL7fD4hbGa5CffJPFqhchOdT5qvr69wc3OTdaM8Pz+HhoYG8Hq9MD4+DjMzM9De3i5+gEAgIGL2oaGhgr5fsfoA+ePVFNMwxvb29nKGRyMjI+nQMBAIMJfLJcLB3t5eFg6HC/7+iMUrkZUrOUl+19rzYfErht9ES+3XuVvk0VPmWPTW2iv38sput0NLS0s6HlfpRvpzLHpesJU8LCw3SHBklBXc6XTC1NSUEmXhMsei3E3T6ihr4VaFBEeGBEeGBEeGBEdGWcFXSrDuIUaCXEnBQ6EQTExMiNj39PRUJK15Ivrx8dHQflES5ExBuopY91AWRiTIOcpZ+Nf3uoeZieh86x5ioSdBngvlBH/Ks+7hvxLRGOhJkJtCcKujnOCNGtc9xEJPgtwUgjsUXfdQWoKcKchGEeseFkM8HmdnZ2eicWkWFhbE33d3d+Lz2dlZMY6dnR12cXHBBgcHmc/nY+/v7wX3oaTgxax7WAxGJ8g59D4cGeV8uNUhwZEhwZEhwZEhwZEhwZEhwZEhwZEhwZEhwZEhwQGXvwYka1asQorZAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 1000\n",
    "Liste = [(0,0)]*N \n",
    "images = [0]*N\n",
    "labels = [0]*N\n",
    "for i in range(0, N): \n",
    "    Liste[i]= generate_image(12, 12)\n",
    "    images[i]=Liste[i][0]\n",
    "    labels[i]=Liste[i][1]\n",
    "\n",
    "images= torch.stack(images, dim=0)\n",
    "labels = torch.LongTensor(labels)\n",
    "\n",
    "\n",
    "#la dimension de images (Tensor de taille n*channels*heigth*width)\n",
    "#ici 1000*1(niveaux de gris)*12*12\n",
    "#labels : Tensor d'ordre n avec des entiers (long tensor)\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(images, labels)\n",
    "trainloader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True, drop_last=True)\n",
    "\n",
    "for i in range (1, 11):\n",
    "    plt.subplot(1, 10, i)\n",
    "    plt.imshow(images[i].squeeze(), cmap = \"gray\") #supprime les dimensions égales à 1 (channel)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "414469c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFwAAABZCAYAAACzIkPrAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABI5JREFUeJztnE1Iak8UwI/2R4soIyJNSnLRuqAwWhe0itq1S9q0aRPtWlibwCiIKIKW7UpaVLs2EbTpA/qgRSAFEULYxyK16AN0/pzhPcmXvOe1e4/j9fxgwHv1eoef48zRmTMWIYQAhgwr3a0YFl4AuIUTw8KJYeHEsHBiWDgxLJwYFk4MCzeL8OXlZWhuboby8nLo7OyE4+Njo25VVFiM+C8lFArB0NAQrKysSNkLCwuwsbEB4XAY6uvr/3ptKpWCu7s7qKqqAovFAqqC2hKJBLjdbrBaNbRbYQA+n0+Mjo6mj5PJpHC73SIYDP7z2kgkgg2gaArWVwu6dymfn59wcnICPT096XPYAvD44ODg2+s/Pj4gHo+nS7H9eYnfRC3oLvzp6QmSySQ4nc6M83gcjUa/vT4YDILD4UgXj8cDxYTWbq/gUcrExATEYrF0iUQi8jw+xtauasH65cN/OvuDuro6KCsrg/v7+4zzeOxyub693m63y1Iq6N7CbTYbtLe3w+7ubkbkgcddXV1Q6ujewpHx8XHw+/3Q0dEBPp9PhoWvr68wPDwMpY4hwgcHB+Hx8REmJyflQNnW1gY7OzvfBtJSxJAfPj8hHo/LaAUHperqalCVfOtZ8Cil1GDhxLBwYlg4MSycGBZODAsnhoWb4ZemHjgcDjAj3MKJYeHEsHBiWDgxLJwYFk4MCyeGhRPDwolh4cSwcGJYODEsnBgWTgwLV134/v4+9PX1yZX/uFR3a2sr43lcV4QrrhoaGqCiokKuC7+6utKzzqUlHNcItra2yhyebMzOzsLi4qJMNzk6OoLKykro7e2F9/d3Pepb/IgfgJdvbm6mj1OplHC5XGJubi597vn5WdjtdrG2tpbTe8ZisYKnkWgpWF8t6NqH39zcyMWbX9NNcKoME6uypZtkSznBYmZ0Ff47pSTXdJNsKSdNTU1gZpRNOTErugr/nVKSa7oJgukmuNz3azEzugr3er1S7Nd0E+yTMVrhdJM816W8vLzA9fV1xkB5fn4OtbW1MuVvbGwMpqenoaWlRX4AgUBAxuwDAwM5vb9i+QH611dTTCOE2Nvbyxoe+f3+dGgYCASE0+mU4WB3d7cIh8M5v3/E5JnIyqWcpH7l2mO18BuDg2ih+3XsFjF6+lqXfHPtlVvqZrVaobGxMR2PqzSQ/lmXfJbjFTwsLDVYODHKCrfb7TA1NaVEWriedVFu0DQ7yrZws8LCiWHhxLBwYlg4McoKXy7AvocUE+RKCg+FQnKTG4x9T09P5aQ1TkQ/PDwYel+SCXKhIL4f7HuoF0ZMkCPKtfBPjfseUpHPBHk2lBP+pHHfQyrymSAvCuFmRznhdRr3PaQinwnyohBuU3TfQ90myIWCrK+vy9F/dXVVXF5eipGREVFTUyOi0aih900kEuLs7EwWVDM/Py8f397eyudnZmZkPba3t8XFxYXo7+8XXq9XvL295XwPJYUjS0tLwuPxCJvNJsPEw8NDYTRGT5Aj/H84Mcr14WaHhRPDwolh4cSwcGJYODEsnBgWTgwLJ4aFE8PCgZb/AfH5nnnsH95aAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFwAAABZCAYAAACzIkPrAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABGtJREFUeJztnM1LKlEUwI/2cIooIyRNSnLRukVgtC5oFfUX1K5Nm2jnwtoERkFEIbRsl9Ki+gMiaNMH9EGLQAoihLBwkVpUgt7HvbwGfcl7js4c74znBxea0Zm5/LreOTP3nmtjjDEg0LDjXYog4XWAWjgyJBwZEo4MCUeGhCNDwpEh4ciQcKsIj0Qi0NfXB83NzTA0NATn5+dGXcpU2Ix4lxKLxWBqagq2traE7PX1ddjd3YV4PA5dXV3/PLZQKMDT0xO0tbWBzWYDWeHastkseL1esNs1tFtmAIFAgM3Ozqrb+Xyeeb1eFg6H/3tsIpHgDcA0hddXC7p3KblcDi4uLmB0dFTdx1sA3z45Ofnx/a+vL8hkMmox28tL/kvUgu7CU6kU5PN5cLvdJfv5djKZ/PH9cDgMTqdTLT6fD8yE1m6v7lFKMBiEdDqtlkQiAVbml94ndLlc0NTUBM/PzyX7+bbH4/nxfUVRRGkUdG/hDocDBgcH4fDwsCTy4NvDw8N6X858MAOIRqNMURS2vb3Nbm9v2czMDOvo6GDJZPK/x6bT6bpHHloKr68WDBHO2dzcZD6fjzkcDhEmnp6eVnSc1YUb8uBTC5lMRkQrZoHf6Nvb280TpTQaJBwZEo4MCUeGhCNDwpEh4ciQcLO/vKrXA4VZHtCohSNDwpEh4ciQcGRIODIkHBkSjgwJR4aEI0PCkSHhyJBwZEg4MtK+LXSaaKqEFqiFyy78+PgYxsfHxcx/PlV3f3+/5HM+r2hhYQG6u7uhpaVFzAu/u7vTs86NJfz9/R0GBgZEDk85VlZWYGNjQ6SbnJ2dQWtrK4yNjcHn56ce9TU/rAb44Xt7e+p2oVBgHo+Hra6uqvteX1/FxM6dnZ2Kzmn1uYW69uEPDw8iy6E43YTf/HhiVbl0k3IpJ7xYGV2Ff6eUVJpuUi7lpLe3F6xM3aOUYIOlnOgq/DulpNJ0Ew5PN+Gj88XFyugq3O/3C7HF6Sa8T+bRCqWbVPmk+fb2Bvf39yU3yuvra+js7BQpf3Nzc7C0tAT9/f3iHxAKhUTMPjk5WdH5JcsP0L++mmIaxtjR0VHZ8Gh6eloNDUOhEHO73SIcHBkZYfF4vOLzJyyeiSxdyknhT649rxb/xfCbaL37dd4t8uipuC7V5tpL9/LKbrdDT0+PGo/LdCP9uy401c0E1D0ObzSkFa4oCiwuLkqRFq5nXaS7aVodaVu4VSHhyJBwZEg4MiQcGWmFR+qw7iHGALmUwmOxGMzPz4vY9/LyUgxa84Hol5cXQ6+LMkDOJCRQw7qHemHEADlHuhae07juIRbVDJCXQzrhKY3rHmJRzQC5KYRbHemEuzSue4hFNQPkphDukHTdQ90GyJmERGtY97AWstksu7q6EoWrWVtbE38/Pj6Kz5eXl0U9Dg4O2M3NDZuYmGB+v599fHxUfA0phdey7mEtGD1AzqH34chI14dbHRKODAlHhoQjQ8KRIeHIkHBkSDgyJBwZEo4MCQdcfgPm0dc/QoheLwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFwAAABZCAYAAACzIkPrAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABH9JREFUeJztnDtIK0EUQG/iI6uIRkRMDBpMYa0gKNYKVqKdnXY2NmJnEW2EiIKIIljaabBQOxsRbPyAHyyEoCASkPgpTKL4gWQeMzwX8wzvZZPZm9nNPTDobrLZ4TiZue7MHQdjjAGBhhPvVgQJLwLUwpEh4ciQcGRIODIkHBkSjgwJR4aE20X48vIyNDc3Q3l5OXR2dsLx8bFZt7IUDjOepYTDYRgaGoKVlRUhe2FhATY2NiASiUB9ff0/r02n03B3dwdVVVXgcDhAVbi2ZDIJPp8PnE4D7ZaZQEdHBxsdHdWPU6kU8/l8LBQK/ffaaDTKG4BlCq+vEaR3KZ+fn3BycgI9PT36Od4C+PHBwcGP9398fEAikdCL1R5e8m+iEaQLf3p6glQqBR6PJ+M8P47FYj/eHwqFwO1268Xv94OVMNrtFT1KmZiYgHg8rpdoNAp25pfsD6yrq4OysjK4v7/POM+PvV7vj/drmiZKqSC9hbtcLmhvb4fd3d2MyIMfd3V1yb6d9WAmsL6+zjRNY6urq+zy8pKNjIywmpoaFovF/nttPB4Xoz//qTL51lN6l8IZHByEx8dHmJycFANlW1sb7Ozs/BhISxFT/vEphEQiIaIVPoBWV1eDquRbz6JHKaUGCUeGhCNDwpEh4ciQcGRIODIkHBkSjgwJR4aEI2PKwysZuN1usCPUwpEh4ciQcGRIODIkHBkSjgwJR4aEI0PCkSHhyJBwZEi46sL39/ehr69PrPznS3W3trYyXufriviKq4aGBqioqBDrwq+urmTWubSEv76+Qmtrq8jhycbs7CwsLi6KdJOjoyOorKyE3t5eeH9/l1Ff61PIgkZ++ebmpn6cTqeZ1+tlc3Nz+rnn52exsHNtbc3QIkmrFKOLOaX24Tc3N2Lx5vd0E/5cmydWZUs3yZZywoudkSr8K6Uk13STbCknTU1NYGeKHqVMlFjKiVThXykluaabcHi6CV/u+73YGanCA4GAEPs93YT3yTxaoXSTPCeRX15e4Pr6OmOgPD8/h9raWpHyNzY2BtPT09DS0iL+AMFgUMTsAwMDOX2+YvkB8utrKKZhjO3t7WUNj4aHh/XQMBgMMo/HI8LB7u5uFolEcv78qM0zkZVLOUn/ybXn1eLfGD6IFrtf590ij56+1yXfXHvl1qU4nU5obGzU43GVBtK/65LP2pmih4WlBglHRlnhmqbB1NSUEmnhMuui3KBpd5Rt4XaFhCNDwpEh4ciQcGSUFb5chH0PMSbIlRQeDodhfHxcxL6np6di0ppPRD88PJh6X5QJcqYgHQXseygLMybIOcq18E+D+x5ikc8EeTaUE/5kcN9DLPKZILeEcLujnPA6g/seYpHPBLklhLsU3fdQ2gQ5U5D1AvY9LIRkMsnOzs5E4Wrm5+fF77e3t+L1mZkZUY/t7W12cXHB+vv7WSAQYG9vbznfQ0nhnKWlJeb3+5nL5RJh4uHhITMbsyfIOfQ8HBnl+nC7Q8KRIeHIkHBkSDgyJBwZEo4MCUeGhCNDwpEh4YDLb/QdeHwg0vnJAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFwAAABZCAYAAACzIkPrAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABI1JREFUeJztnDtLK0EUgE/iJauID0RMDBpMYW0hKNYKVqK/QDsbG7GziDZCREFEESztNFioP0AEGx/gAwshKIgEJIqFSRQfkJzLDLqYa7hmk92T2c35YMBds9nhy+zs2Z0540JEBIYMN92pGBZeAriFE8PCiWHhxLBwYlg4MSycGBZODAt3ivCVlRVoa2uDyspK6O7uhuPjY6tOZStcVrxLiUQiMDw8DKurq1L24uIibG5uQjQahaampv8em8lk4O7uDmpqasDlcoGqCG2pVAr8fj+43QbaLVpAV1cXjo2N6dvpdBr9fj+Gw+Ffj43FYqIB2KaI+hrB9C7l4+MDTk5OoK+vT98nWoDYPjg4+PH59/d3SCaTerHby0txJRrBdOGPj4+QTqfB6/Vm7Rfb8Xj8x+fD4TDU1dXpJRAIgJ0w2u2VPEqZnJyERCKhl1gsBk7mj9lf2NjYCBUVFXB/f5+1X2z7fL4fn9c0TZZywfQW7vF4oLOzE3Z3d7MiD7Hd09Nj9unsB1rAxsYGapqGa2treHl5iaOjo1hfX4/xePzXYxOJRMkjDyNF1NcIlggXLC8vYyAQQI/HI8PEw8PDvI5zunBLHnyKIZlMymjFLogbfW1trX2ilHKDhefBZ9ebVUTLLgQWTgwLt/uDjxNAC+MIbuHEsHBiWDgx3Id/QvX8xy2cGBZOTNl2KViiV0jcwolh4cSwcGLKpg9HRV77cwsnhoUTw8KJcXQfjhb028VOMOUWTgwLJ8ZRXQpaFPqZOU+dWzgxhoXv7+/DwMCAnPkvfvnt7e0frWxqagqam5uhqqpKzgu/uroys87lJfzl5QU6OjpkDk8u5ubmYGlpSaabHB0dQXV1NfT398Pb25sZ9bU/WATi8K2tLX07k8mgz+fD+fl5fd/T05Oc2Lm+vm7J3EIrsHJuoal9+M3Njcxy+J5uIuYJisSqXOkmuVJORHEypgr/SinJN90kV8pJa2srOJmSRymTiqSciADgq9hG+FdKSb7pJgKRbiKm+34vTsZU4cFgUIr9nm4i+mQRrXC6SYFPms/Pz3B9fZ11ozw/P4eGhgaZ8jc+Pg4zMzPQ3t4uf4BQKCRj9qGhIUueFkt9kzX8dGs0ZNrb28sZHo2MjOihYSgUQq/XK8PB3t5ejEajeX9/zOGZyMqlnGQ+c+1FtcQVI26ipe7XxVUkoqfvdSk01165l1dutxtaWlr0rkKlG+m/dSkkF6nkYWG5wcKJUVa4pmkwPT2tRFq4mXVR7qbpdJRt4U6FhRPDwolh4cSwcGKUFb5SgnUPKQbIlRQeiURgYmJCxr6np6dy0FoMRD88PFh6XpIBclSQriLWPTQLKwbIBcq18A+D6x5SUcgAeS6UE/5ocN1DKgoZILeFcKejnPBGg+seUlHIALkthHsUXffQtAFyVJCNItY9LIZUKoVnZ2eyCDULCwvy79vbW/n/2dlZWY+dnR28uLjAwcFBDAaD+Pr6mvc5lBRezLqHxWD1ALmA34cTo1wf7nRYODEsnBgWTgwLJ4aFE8PCiWHhxLBwYlg4MSwcaPkLopQ2gfv4es4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFwAAABZCAYAAACzIkPrAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABMFJREFUeJztnDtLK0EUx8/GS6KID0RMDBpMYW0hKNYKVqKfQDsbG7FLEUUQIgoiimBpp8FC/QAi2PgAH1iIQUEkIFEsjFF8QDKXGW5CvObmZjezZyeb84MBd5PdGf979uzJnjmjMcYYEGg48LoiSHALIAtHhgRHhgRHhgRHhgRHhgRHhgRHhgS3i+ArKyvQ1tYGlZWV0N3dDcfHx2Z1VVJoZrxLCYfDMDw8DKurq0LsxcVF2NzchEgkAk1NTXmPTaVScH9/DzU1NaBpGqgKly2RSIDX6wWHQ4fdMhPo6upiY2Njme1kMsm8Xi8LhUL/PTYajXIDKJnGx6uHX7Kv/NfXF5ycnEAgEMjs4xbQ19cHBwcHP77/+fkpWpYB6OovHo+DDOrq6gwdx+9EPUgX/OnpCZLJJLjd7m/7+fbV1dWP74dCIZienjbcX21tLViJXrdneZQSCASElaZbNBq1ZBz8zko3M5Fu4Y2NjVBRUQEPDw/f9vNtj8fz4/sul0u0ckG6hTudTujs7ITd3d1vkQff7unpkd1d6cFMYGNjg7lcLra2tsYuLy/Z6Ogoq6+vZ7FY7L/HxuNxwxGDWeTrk49X17nMGuTy8jLz+XzM6XSKMPHw8LCg4+wuuCk/fIrh5eXFcIhm1r+SLxLhD3o9kZLlUUq5IT1KsRLtL0uUZfHZ5yn2dQNZODIkODK2FlzTtEyTRfrXqNF3OLYWXEVIcGRIcGRsFRZaETLqhSwcGRIcmbJxKaq4GLJwZEhwZEhwZMrWh+fz6Wb6c7JwZEhwZEhwZMiHI8foZOHIkODIkEspAJkZI7JwZHQLvr+/DwMDA2LmP7/y29vbPx4wk5OT0NzcDFVVVWJe+PX1tcwxl5fgb29v0NHRIWp4cjE3NwdLS0ui3OTo6Aiqq6uhv78fPj4+ZIy39Cl2zt3W1lZmO5VKMY/Hw+bn5zP7np+fxcTO9fV10+cWWtH0zi2U6sNvb28hFosJN5KGzxPkhVW5yk04vNyEzyfMbnZGquBcbE6ucpP0Z7lKTvhFSbfW1lawM5ZHKQFFSk5KUvB0SUmh5SYcXm7Cp/tmNzsjVXC/3y+EzS434T6ZRytUbmLwl+br6yvc3Nx8e1Cen59DQ0MD+Hw+GB8fh5mZGWhvbxcXIBgMiph9aGiooPMrVh8gf7y6YhrG2N7eXs7waGRkJBMaBoNB5na7RTjY29vLIpFIweeP2rwSWbmSk9SfWns+LH7H8Ieo1X6du0UePWWPxWitvXIvrxwOB7S0tGTicZUepH+PxUgtkuVhYblBgiOjrOAulwumpqaUKAuXORblHpp2R1kLtyskODIkODIkODIkODLKCr5iwbqHGAlyJQUPh8MwMTEhYt/T01ORtOaJ6MfHR1P7RUmQMwXpKmLdQ1mYkSDnKGfhX3/WPcxOROdb9xALIwnyXCgn+FOedQ//lYjGwEiCvCQEtzvKCd6oc91DLIwkyEtCcKei6x5KS5AzBdkoYt3DYkgkEuzs7Ew0Ls3CwoL4++7uTnw+OzsrxrGzs8MuLi7Y4OAg8/v97P39veA+lBS8mHUPi8HsBDmH3ocjo5wPtzskODIkODIkODIkODIkODIkODIkODIkODIkODIkOODyGw1Zeh1ZhpE6AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFwAAABZCAYAAACzIkPrAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABJdJREFUeJztnDtLK0EUx0/iJauID0RMDBpMYW0hKNYKVqKfQDsbG7GziDZCREFEESztNFioH0AEGx/gAwshKIgEJIqFSRQfkMxl5l6XRMO92WT2ZGY9Pxhw1p3d4Z+zZ87uzBkXY4wBgYYb71YECV4GyMKRIcGRIcGRIcGRIcGRIcGRIcGRIcGdIvjKygq0tbVBZWUldHd3w/HxsV230gqXHd9SIpEIDA8Pw+rqqhB7cXERNjc3IRqNQlNT0z/bZjIZuLu7g5qaGnC5XKAqXLZUKgV+vx/cbgt2y2ygq6uLjY2NmfV0Os38fj8Lh8P/bRuLxbgBaFN4f60g3aV8fHzAyckJ9PX1mce4BfD6wcHBt/Pf398hmUyaRbePl/xJtIJ0wR8fHyGdToPX6805zuvxePzb+eFwGOrq6swSCARAJ6y6vbJHKZOTk5BIJMwSi8XAyfySfcHGxkaoqKiA+/v7nOO87vP5vp1vGIYoPwXpFu7xeKCzsxN2d3dzIg9e7+npkX07/WA2sLGxwQzDYGtra+zy8pKNjo6y+vp6Fo/H/9s2kUiUPfKwUnh/rWCL4Jzl5WUWCASYx+MRYeLh4WFB7ZwuuC0vPqWQTCZFtKILfKCvra3VJ0r5abhVthz2x+WBk1BWcKdCguv+4mMHLMutqPwFsRDIwpEhwZEhwZHRwodn8zVM1M2nk4UjQ4Ijo51L0T1kJAtHhgRHhgRHRnsfrlvISBaODAmODAmOjKN8uA4xOlk4MiQ4Msq6lLqspRIyJpJVCRnJwlUXfH9/HwYGBsTKf24l29vb3yxpamoKmpuboaqqSqwLv7q6ktnnnyX4y8sLdHR0iByefMzNzcHS0pJINzk6OoLq6mro7++Ht7c3Gf3VH1YCvPnW1pZZz2QyzOfzsfn5efPY09OTWNi5vr4uZW2hXWCtLZTqw29ubkSWQ3a6CR/8eGJVvnSTfCknvDgZqYJ/ppQUmm6SL+WktbUVnIx2KSculyunyOJzHaPdaxmlCv6ZUlJougmHp5vw5b7ZxclIFTwYDAphs9NNuE/m0QqlmxT5pvn8/AzX19c5A+X5+Tk0NDSIlL/x8XGYmZmB9vZ28QOEQiERsw8NDRV0fauPdLkHWcsuyGr4tLe3lzc8GhkZMUPDUCjEvF6vCAd7e3tZNBot+Poxh2ciK5dykvmba8+7xZ8YPoiW26/zp4hHT9l9KTbXXrmPV263G1paWkxXodJA+rUvxeQilT0s/GmQ4MgoK7hhGDA9Pa1EWrjMvig3aDodZS3cqZDgyJDgyJDgyJDgyCgr+EoZ9j3EmCBXUvBIJAITExMi9j09PRWT1nwi+uHhwdb7okyQMwXpKmHfQ1nYMUHOUc7CPyzue4hFMRPk+VBO8EeL+x5iUcwEuRaCOx3lBG+0uO8hFsVMkGshuEfRfQ+lTZAzBdkoYd/DUkilUuzs7EwULs3CwoL4+/b2Vvx/dnZW9GNnZ4ddXFywwcFBFgwG2evra8H3UFLwUvY9LAW7J8g59D0cGeV8uNMhwZEhwZEhwZEhwZEhwZEhwZEhwZEhwZEhwZEhwQGX3yriPLdVVQ19AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFwAAABZCAYAAACzIkPrAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABGxJREFUeJztnDtLK0EUgE/iJauIRiSYGDSYwtpCUKwVrER/gXY2NmJnEW2EiIKIIljaabBQf4AINj7ABxZCUBAJSBQLkyg+IJnLGa6LuYZ7s8nuyex6PhhwN9ns8DmZPZmZMy4hhACGDDfdrRgWXgG4hRPDwolh4cSwcGJYODEsnBgWTgwLd4rwlZUVaGtrg+rqauju7obj42OrbmUrXFaMpcRiMRgeHobV1VUpe3FxETY3NyEej0NTU9M/r83lcnB3dwd1dXXgcrlAVVBbJpOBYDAIbreBdissoKurS4yNjenH2WxWBINBEY1G/3ttIpHABmCbgvU1guldysfHB5ycnEBfX59+DlsAHh8cHHx7//v7O6TTab3YbfASv4lGMF344+MjZLNZ8Pv9eefxOJlMfnt/NBoFr9erl1AoBHbCaLdX8ShlcnISUqmUXhKJBDiZX2Z/oM/ng6qqKri/v887j8eBQODb+zVNk+WnYHoL93g80NnZCbu7u3mRBx739PSYfTv7ISxgY2NDaJom1tbWxOXlpRgdHRUNDQ0imUz+99pUKlXxyMNIwfoawRLhyPLysgiFQsLj8cgw8fDwsKjrnC7ckh8+5ZBOp2W0YhfwQV9fX2+fKOWnwcKJYeHEsHBiWDgxLJwYFk4MCyeGhRPDwolh4cSwcGJYODEsnBgWbvc5zUqNM9tl3J5bODEsnBgWTgwLJ4aFE8PCiWHhxLBw1YXv7+/DwMCAXPmPS3W3t7fzXsd1RVNTU9Dc3Aw1NTVyXfjV1ZWZdf5Zwl9eXqCjo0Pm8BRibm4OlpaWZLrJ0dER1NbWQn9/P7y9vZlRX/sjygAv39ra0o9zuZwIBAJifn5eP/f09CQXdq6vrxtaW2h0zR41pdbT1D785uZGZjl8TTfB8QZMrCqUblIo5QSLkzFV+GdKSbHpJoVSTlpbW8HJKJty4vV65UNZ1VLqCl9ThX+mlBSbboJgugkOw34tTsZU4eFwWIr9mm6CfTJGK5xuUuIExPPzM1xfX+c9KM/Pz6GxsVGm/I2Pj8PMzAy0t7fLf0AkEpEx+9DQUFGfr1h+gPn1NRoO7e3tFUy9GBkZ0UPDSCQi/H6/DAd7e3tFPB4v+vMTDs9EVi7lJPcn1x6rhd8YfIhWul/HbhGjp691KTXXXrk5TbfbDS0tLXo8rtKD9O+68JymDah4HP7TUFa4pmkwPT2tRFq4mXVR7qHpdJRt4U6FhRPDwolh4cSwcGKUFb5SgX0PKSbIlRQei8VgYmJCxr6np6dy0honoh8eHiy9L8kEuVCQrjL2PTQLKybIEeVa+IfBfQ+pKGWCvBDKCX80uO8hFaVMkNtCuNNRTrjP4L6HVJQyQW4L4R5F9z00bYJcKMhGGfselkMmkxFnZ2eyoJqFhQX59+3trXx9dnZW1mNnZ0dcXFyIwcFBEQ6Hxevra9H3UFJ4OfseloPVE+QIj4cTo1wf7nRYODEsnBgWTgwLJ4aFE8PCiWHhxLBwYlg4MSwcaPkNMApSHwaiuWYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFwAAABZCAYAAACzIkPrAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABINJREFUeJztnMtLckEUwI/24S2iByFpUpKL1i0Co3VBq6i/oHZt2kQ7FxZBYBREFEHLdiktqj8ggjY9oActIimIEMLCRWbRA3Q+ZkixL7/yvo7j9fxgoHv1OtPPce7RmTM2xhgDAg07XlUECS8B1MORIeHIkHBkSDgyJBwZEo4MCUeGhFtF+MrKCrS3t0N1dTV0d3fD0dGRWVWVFTYzfkuJRCIwPDwMq6urQvbi4iJsbGxANBqF5ubmH6/NZDJwd3cHdXV1YLPZQFa4tlQqBR6PB+x2Ff2WmYDf72djY2O543Q6zTweDwuFQr9eG4vFeAcom8Lbq4Y/Rr/zHx8fcHx8DIFAIHeO94C+vj7Y39//9vz393dR8jqA5rqTyaTmaxsaGjRdxz+JajBceCKRgHQ6DS6X68t5fnx5efnt+aFQCKanpw2pu76+HrBRO+yVPEoJBAKiZ2ZLLBYDK2N4D3c6nVBVVQX39/dfzvNjt9v97fmKoohSKRjewx0OB3R1dcHOzs6XyIMf9/T0GF1d+cFMIBwOM0VR2NraGru4uGCjo6OssbGRxePxX69NJpOaIwY9aK2Tt1dVPcwklpeXmdfrZQ6HQ4SJBwcHRV1ndeGmfPHRw9PTk+YQTc+/ovVLFr/Rq4mOSh6lVBokHBkSjgwJR4aEI0PCkSHhyJBwZEg4MiQcGRKODAlHhoQjQ8KRIeHIkHBkSDgyJBwZEo4MCUeGhCNDwpEh4ciQcNmF7+3twcDAgFj5zxfPbG1tfVuMMzk5CS0tLVBTUyPWhV9dXRnZ5soS/vLyAp2dnSKHpxBzc3OwtLQk0k0ODw+htrYW+vv74e3tzYj2lj961+Ntbm7mjjOZDHO73Wx+fj537vHxUSzsXF9fL+o1rb620NAx/ObmBuLxuBhGsvB1gjyxqlC6CYenm/D1hPnFyhgqnMvmFEo3yT5WKOWEvynZ0tbWBlam5FFKoMJSTgwVnk0pKTbdhMPTTfhy3/xiZQwV7vP5hNj8dBM+JvNohdJNNCZVPT8/w/X19Zcb5dnZGTQ1NYHX64Xx8XGYmZmBjo4O8QYEg0ERsw8NDZm+qL4UN1zV7VUbPu3u7hYMj0ZGRnKhYTAYZC6XS4SDvb29LBqNFv36MYtnIkuXcpL5zLXnzeKfGH4TLfW4zj85PHrKb4vWXHvD8zT1YrfbobW1NTc8yHQj/bctWnKRSh4WVhokHBlphSuKAlNTU1KkhRvZFulumlZH2h5uVUg4MiQcGRKODAlHRlrhKyXY9xBjglxK4ZFIBCYmJkTse3JyIiat+UT0w8ODqfWiTJAzCfHr2PfQKMyYIOdI18M/Pvc9zJ+I/mnfQyy0TJAXQjrhiR/2PfzfRDQGWibIy0K41ZFOuFPlvodYaJkgLwvhDkn3PTRsgpxJSFjHvod6SKVS7PT0VBSuZmFhQfx9e3srHp+dnRXt2N7eZufn52xwcJD5fD72+vpadB1SCtez76EezJ4g59Dv4chIN4ZbHRKODAlHhoQjQ8KRIeHIkHBkSDgyJBwZEo4MCQdc/gJpiVwU3MC31QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFwAAABZCAYAAACzIkPrAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABL5JREFUeJztnDtLK0EUx0/iJVHEByImBg2msLYQFGsFK9FPoJ2NjdiliCIIEQURRbC002ChfgARbHyADyzEoCASkCgWxig+IJnLDCYkmpub3cyezG7ODwbczW5m/Ofs2bN75oyNMcaAQMOO1xVBgpcAsnBkSHBkSHBkSHBkSHBkSHBkSHBkSHCrCL6ysgJtbW1QWVkJ3d3dcHx8bFRXpsJmxLuUUCgEw8PDsLq6KsReXFyEzc1NCIfD0NTUlPfcZDIJ9/f3UFNTAzabDVSFyxaPx8Hj8YDdrsFumQF0dXWxsbGx9HYikWAej4cFg8H/nhuJRLgBmKbx8Wrhj+xf/uvrC05OTsDv96f3cQvo6+uDg4ODX8d/fn6KlmEAuvuOxWIgg7q6uoKP5VeiFqQL/vT0BIlEAlwuV9Z+vn11dfXr+GAwCNPT01L6rq2tBWy0ur2SRyl+v19YZqpFIhFN5/MrItXMgHQLb2xshIqKCnh4eMjaz7fdbvev451Op2jlgnQLdzgc0NnZCbu7u1mRB9/u6emR3Z35YAawsbHBnE4nW1tbY5eXl2x0dJTV19ezaDT633NjsVjeqMAo9EYpfLya+jHqH1heXmZer5c5HA4RJh4eHhZ0ntUFN+TBpxheXl7yhmVGDVfvQxa/0WuJjkoepZQb0qMUI2AGWHWpXhuQhSNDgiOjrOCxWEzqEyR3IZmtVCgruFUhwZEhwZExRVioFxUzRmThyJDgyFjKpdgUdCE/IQtHhgRHhgRHxvQ+3GYCv50JWTgyJDgyJDgypvPhNpP57J+QhSNDgiOjrEup0zCD1UyQhasu+P7+PgwMDIiZ//wGtr29nfU5z0FOTk5Cc3MzVFVViXnh19fXMsdcXoK/vb1BR0eHqOHJxdzcHCwtLYlyk6OjI6iurob+/n74+PiQMV7zU+x8vK2trfR2Mplkbrebzc/Pp/c9Pz+LiZ3r6+tS5haq1rTOLZTqw29vbyEajQo3knnz44VVucpNOLzchM8nzGxWRqrgXGxOrnKT1Ge5Sk74j5Jqra2tYGVMX3JS1oKnSkoKLTfh8HITPt03s1kZqYL7fD4hbGa5CffJPFqhchOdT5qvr69wc3OTdaM8Pz+HhoYG8Hq9MD4+DjMzM9De3i5+gEAgIGL2oaGhgr5fsfoA+ePVFNMwxvb29nKGRyMjI+nQMBAIMJfLJcLB3t5eFg6HC/7+iMUrkZUrOUl+19rzYfErht9ES+3XuVvk0VPmWPTW2iv38sput0NLS0s6HlfpRvpzLHpesJU8LCw3SHBklBXc6XTC1NSUEmXhMsei3E3T6ihr4VaFBEeGBEeGBEeGBEdGWcFXSrDuIUaCXEnBQ6EQTExMiNj39PRUJK15Ivrx8dHQflES5ExBuopY91AWRiTIOcpZ+Nf3uoeZieh86x5ioSdBngvlBH/Ks+7hvxLRGOhJkJtCcKujnOCNGtc9xEJPgtwUgjsUXfdQWoKcKchGEeseFkM8HmdnZ2eicWkWFhbE33d3d+Lz2dlZMY6dnR12cXHBBgcHmc/nY+/v7wX3oaTgxax7WAxGJ8g59D4cGeV8uNUhwZEhwZEhwZEhwZEhwZEhwZEhwZEhwZEhwZEhwQGXvwYka1asQorZAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFwAAABZCAYAAACzIkPrAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABKVJREFUeJztnD1LM0EQxyfxIaeIL4iYGDSYwtpCUKwVrEQ/gXY2NmJnEW2EiIKIIljaabBQP4AINr6AL1gIQUEkIFEsTKL4Ask+7KJHNFFzl7vJ7jk/WHDP27v179zs3O3OuhhjDAg03Hi3IkjwEkAWjgwJjgwJjgwJjgwJjgwJjgwJjgwJ7hTBl5aWoKWlBcrLy6GzsxMODw/tupVSuOz4lhKJRGBwcBCWl5eF2PPz87C+vg7RaBQaGhp+bJvJZODm5gaqqqrA5XKBrHDZUqkU+P1+cLsN2C2zgY6ODjYyMqLX0+k08/v9LBwO/9o2FotxA1Cm8P4awXKX8vb2BkdHR9DT06Mf4xbA63t7eznnv76+QjKZ1ItqHy/5k2gEywW/v7+HdDoNXq/303Fej8fjOeeHw2GoqanRSyAQAJUw6vZKHqWMj49DIpHQSywW+/F8/gR8V1Tgn9UXrK+vh7KyMri9vf10nNd9Pl/O+ZqmifJXsNzCPR4PtLe3w/b29qfIg9e7urqsvp16MBtYW1tjmqaxlZUVdn5+zoaHh1ltbS2Lx+O/tk0kEjmRgFkwohTeX0N9YjaxuLjIAoEA83g8Ikzc398vqJ3TBbflxacYksmkiFayMdtFjBcnPtBXV1erE6X8NSyPUmSCZT0ZsnwmIAtHhgRHRgmX4spyB2YH0K/tSuViyMKRIcGRIcGRUcKH/+R7VfPpZOHIkODIKOdS7AgZv7a1072QhSNDgiNDgiOjvA9XLWQkC0eGBEeGBEfGUT5chRidLBwZEhwZR7sUO0LGYiELl13w3d1d6OvrEyv/udVsbm7mWM7ExAQ0NjZCRUWFWBd+cXFhZZ//luBPT0/Q1tYmcnjyMTMzAwsLCyLd5ODgACorK6G3txdeXl6s6K/6mF649752b2NjQ69nMhnm8/nY7Oysfuzh4UEs7FxdXTW9thCj/PZ3WrW20FIffnV1JbIcstNN+DpBnliVL90kX8oJL07GUsE/UkoKTTfJl3LS3NwMTka5lBO74AHAd0VawT9SSgpNN+HwdBO+3De7OBlLBQ8Gg0LY7HQT7pN5tELpJibfNB8fH+Hy8vLTQHl6egp1dXUi5W90dBSmpqagtbVV/ANCoZCI2QcGBgq6vmT5Adb311BMwxjb2dnJGx4NDQ3poWEoFGJer1eEg93d3SwajRZ8/ZjDM5GlSznJvOfa827xJ4YPoqX269wt8ugpuy9mc+2l+3jldruhqalJj8dlGki/9uVrLpISYeFfgwRHRlrBNU2DyclJKdLCreyLdIOm05HWwp0KCY4MCY4MCY4MCY6MtIIvlWDfQ4wJcikFj0QiMDY2JmLf4+NjMWnNJ6Lv7u5svS/KBDmTkI4i9j20CjsmyDnSWfibwX0PsTAzQZ4P6QS/N7jvIRZmJsiVENzpSCd4vcF9D7EwM0GuhOAeSfc9tGyCnEnIWhH7HhZDKpViJycnonBp5ubmxM/X19fi99PT06IfW1tb7OzsjPX397NgMMien58LvoeUghez72Ex2D1BzqHv4chI58OdDgmODAmODAmODAmODAmODAmODAmODAmODAmODAkOuPwHRJ91wrcmcP4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Correction\n",
    "n = 1000\n",
    "height = 12\n",
    "width = 12\n",
    "\n",
    "images = torch.zeros(n, 1, height, width, device = device)\n",
    "classes = torch.LongTensor(n).to(device)\n",
    "\n",
    "for i in range(n):\n",
    "    images[i], classes[i] = generate_image(height, width)\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(images, classes)\n",
    "for i in range (1, 11):\n",
    "    plt.subplot(1, 10, i)\n",
    "    plt.imshow(images[i].squeeze(), cmap = \"gray\") #supprime les dimensions égales à 1 (channel)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb47af6",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "Put the dataset into a `DataLoader`. What are the differences between a dataset and a data loader?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1923cd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5084f3f2",
   "metadata": {},
   "source": [
    "What are Conv2d, Linear and MaxPool?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c149d2",
   "metadata": {},
   "source": [
    "Con2d --> Idée : les masques représentent la reconnaissance d'un **motif local dans l'image**, quand il rencontre le même motif sur l'image, on a un pixel qui va être de grande valeur et inversement, si le motif n'est pas reconnu, le pixel renvoyé sera d'une plus faible valeur. Les réseaux de neurones convolutionnels fonctionnent en **local**, c'est pour ça qu'ils sont efficaces pour les images naturelles. \\\n",
    "Quand on empile les couches de convolutions, on considère des éléments étendus dans l'image pour vu de faire des masques plus grands, ou que l'on empile plusieurs couches. \\\n",
    "Une couche FC serait mieux mais il y a trop de paramètres et ce ne sera pas de l'information locale. \\\n",
    "C'est uniquement pour un canal de sortie et un canal d'entrée (donc il faut multiplier l'opération par le nombre de canaux d'entrée et de sortie). \\\n",
    "**Idée générale** : commencer par 3 canaux (RGB), et augmenter le nombre de canaux (jusqu'à 64) et le mettre dans une couche FC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f2633b",
   "metadata": {},
   "source": [
    "In a dataset, the elements can be accessed individually given an index (with `[i]`). \n",
    "\n",
    "A data loader is an `Iterable`, which means that its elements can only be accessed through an `Iterator` that traverses the dataset in a way that is provided by the arguments of the data loader (batch size, random/deterministic choice of the data points, etc.). In particular, it can be traversed with a `for` loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b077372d",
   "metadata": {},
   "source": [
    "## Simple NN/training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a580ae6",
   "metadata": {},
   "source": [
    "**Question 3**\n",
    "\n",
    "Write a neural network that classifies the data points previously generated. One can use a convolutional and a fully-connected layer.\n",
    "\n",
    "What are the parameters of a convolutional layer? What is their shape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83e6ef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallCVNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallCVNN, self).__init__()\n",
    "\n",
    "        self.act_function = torch.relu\n",
    "        layer = [1, 6, 4]\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(layer[0], layer[1], 5)\n",
    "        self.fc = torch.nn.Linear(4*4*layer[1], layer[2])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.act_function(x)\n",
    "        x = torch.nn.functional.max_pool2d(x, 2)\n",
    "\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc(x)\n",
    "        x = torch.nn.functional.log_softmax(x, dim = 1)\n",
    "\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed3549d",
   "metadata": {},
   "source": [
    "Parameters: `conv.bias`, `conv.weight`.\n",
    "\n",
    "`conv.bias`: size `out_channels`\n",
    "\n",
    "`conv.weight`: size `out_channels` * `in_channels` * `kernel_height` * `kernel_width`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "335f81f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, nepochs):\n",
    "    #List to store loss to visualize\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    start_epoch = 0\n",
    "\n",
    "    for epoch in range(start_epoch, nepochs):\n",
    "        train_loss = 0.\n",
    "        valid_loss = 0.\n",
    "        correct = 0\n",
    "\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(data_loader):\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "\n",
    "            # update training loss\n",
    "            train_loss += loss.item() * data.size(0)\n",
    "            \n",
    "            # accuracy\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "\n",
    "        # calculate average losses\n",
    "        train_loss = train_loss/len(data_loader.dataset)\n",
    "        accuracy = correct/len(data_loader.dataset)*100\n",
    "        train_acc.append(accuracy)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # print losses statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tTraining accuracy: {:.6f}'.format(\n",
    "            epoch, train_loss, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dd6303",
   "metadata": {},
   "source": [
    "**Question 4**\n",
    "\n",
    "Choose the loss and train the NN. Why do we choose to minimize the loss instead of maximizing the accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1bce1b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [128, 144]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      7\u001b[39m optimizer = optim.Adam(model.parameters())\n\u001b[32m      9\u001b[39m nepochs = \u001b[32m10\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, criterion, optimizer, nepochs)\u001b[39m\n\u001b[32m     15\u001b[39m optimizer.zero_grad()\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# forward pass: compute predicted outputs by passing inputs to the model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# calculate the batch loss\u001b[39;00m\n\u001b[32m     21\u001b[39m loss = criterion(output, target)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\camil\\Desktop\\L2\\TP_Deep_Learning_L3\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\camil\\Desktop\\L2\\TP_Deep_Learning_L3\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mSmallCVNN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     12\u001b[39m     x = x.view(x.size(\u001b[32m0\u001b[39m),-\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.act_function(x)\n\u001b[32m     15\u001b[39m     x = torch.nn.functional.max_pool2d(x, \u001b[32m2\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\camil\\Desktop\\L2\\TP_Deep_Learning_L3\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\camil\\Desktop\\L2\\TP_Deep_Learning_L3\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\camil\\Desktop\\L2\\TP_Deep_Learning_L3\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:553\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    552\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\camil\\Desktop\\L2\\TP_Deep_Learning_L3\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    537\u001b[39m         F.pad(\n\u001b[32m    538\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    545\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    546\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [128, 144]"
     ]
    }
   ],
   "source": [
    "model = SmallCVNN()\n",
    "\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "nepochs = 10\n",
    "\n",
    "train_model(model, criterion, optimizer, nepochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c1441d",
   "metadata": {},
   "source": [
    "The derivative of the accuracy w.r.t. the parameters of the NN is zero, so the NN cannot be trained with this \"loss\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314aacf1",
   "metadata": {},
   "source": [
    "# Variational Auto-Encoders (VAE): MNIST and FashionMNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd960b53",
   "metadata": {},
   "source": [
    "## Building a standard fully-connected VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54feff84",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "Complete the class `VAE_FC`:\n",
    " * build an encoder module;\n",
    " * build a decoder module;\n",
    " * write the method `encode`, which takes an input `x` and returns means and log-variances;\n",
    " * write the method `decode`, which takes a random variable `z` and returns the reconstructed image;\n",
    " * write the method `reparameterization`, taking means and variances and returning normal samples with these means and variances;\n",
    " * write the method `forward`, which takes an input `x` and returns its reconstruction `x_hat`, and the mean/variance of the latent representation.\n",
    "\n",
    "Additionally:\n",
    " * write the method `sample`, which generates new data;\n",
    " * write the method `reconstruct`, which attempts to reconstruct the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d49bb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "#mean, std = .2860, .3530\n",
    "\n",
    "# build transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    ]) \n",
    "\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.MNIST(datasets_path, train = True,\n",
    "                              download = True, transform = transform)\n",
    "test_data = datasets.MNIST(datasets_path, train=False,\n",
    "                             download = True, transform = transform)\n",
    "\n",
    "train_size = len(train_data)\n",
    "test_size = len(test_data)\n",
    "\n",
    "# build the data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "# specify the image classes\n",
    "classes = [f\"{i}\" for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9007b7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#layers: liste de tailles de couches (encoder)\n",
    "k = 2\n",
    "layers = [784, 784//k, 784//(2*k), 784//(3*k)]\n",
    "lst = [nn.Linear(layers[i], layers[i+1]) for i in range (len(layers)-1)]\n",
    "lst2 = [[lst[i//2] for i in range(len(layers)-1)] if i%2 == 0 else nn.ReLU()]\n",
    "\n",
    "\n",
    "class VAE_FC(nn.Module):\n",
    "    def __init__(self, layers, latent_dim = 200, leak = .1):\n",
    "        super(VAE_FC, self).__init__()\n",
    "        self.layers = layers\n",
    "        self.latent_dim = latent_dim\n",
    "        layers = [0, 0, 0]\n",
    "        #encoder\n",
    "        encoder = []\n",
    "        for l_in, l_out in zip[layers[:-1], layers[:1]]:\n",
    "            encoder +=(nn.Linear(l_in, l_out), nn.LeakyReLU(leak))\n",
    "        self.encoder = nn.Sequential(*encoder) #* permet de dérouler la liste, c'est comme si on écrivait encoder[0], ecnoder[1]...\n",
    "    \n",
    "        self.fc_mean = nn.Linear(layers[-1], latent_dim)\n",
    "        self.logvar = nn.Linear(layers[-1], latent_dim)\n",
    "        #couches FC qui prennent qlqc sortie de l'encoder et sortent qlqc qui est dans l'espace latent \n",
    "        #mêmes structures mais entraînées de manières différentes (cf cours avec l'ELBO et KL(latent_space_dist, prior))\n",
    "\n",
    "        self.decoder_input = nn.Linear(latent_dim, layers[-1])\n",
    "\n",
    "        rev_layers = list(reversed(layers))\n",
    "        decoder = [nn.LeakyReLU(leak)]\n",
    "        for l_in, l_out in zip[rev_layers[:-1], rev_layers[:1]]:\n",
    "            decoder +=(nn.Linear(l_in, l_out), nn.LeakyReLU(leak))\n",
    "        decoder += [nn.Linear(layers[1], layers[0]), nn.Sigmoid()]\n",
    "        self.decoder = nn.Sequential(*decoder) \n",
    " \n",
    "\n",
    "    \n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        \n",
    "    def reparameterization(self, mean, logvar):\n",
    "        epsilon = torch.normal(0, 1)\n",
    "        self = mean**2 + torch.mul(logvar, epsilon[1]) \n",
    "\n",
    "\n",
    "    def decode(self, x):\n",
    "        x = self.decoder()\n",
    "       \n",
    "    def forward(self, inputs): \n",
    "        layers = [0, 0, 0]\n",
    "        latent_dim = 0   \n",
    "        self.fc_mean = nn.Linear(layers[-1], latent_dim)\n",
    "        self.fc_logvar = nn.Linear(layers[-1], latent_dim)\n",
    "        \n",
    "    \n",
    "    def sample(self, num_samples): #inférence, pas besoin de tirer qlqc d'aléatoire\n",
    "        pass\n",
    "    \n",
    "    def reconstruct(self, x): #reconstruction à paartir d'un input\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff15532",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "Write the function `build_loss_vae`, which builds the loss function for the VAE. The reconstruction loss and the KL loss will be balanced by two parameters `lambda_reconstruct` and `lambda_kl` (by default, they are equal to 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed80b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_loss_vae():\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f414fdbe",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a66daff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_vae(data_loader, model, criterion, optimizer, nepochs):\n",
    "    #List to store loss to visualize\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    start_epoch = 0\n",
    "\n",
    "    for epoch in range(start_epoch, nepochs):\n",
    "        train_loss = 0.\n",
    "        valid_loss = 0.\n",
    "        correct = 0\n",
    "\n",
    "        model.train()\n",
    "        for batch_idx, (input_, target) in enumerate(data_loader):\n",
    "            input_ = input_.to(device)\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            # ...\n",
    "\n",
    "            # calculate the batch loss\n",
    "            # ...\n",
    "\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "\n",
    "            # update training loss\n",
    "            train_loss += loss.item() * input_.size(0)\n",
    "\n",
    "        # calculate average losses\n",
    "        train_loss = train_loss/len(data_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # print losses statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "            epoch, train_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0000beea",
   "metadata": {},
   "source": [
    "**Question 3**\n",
    "\n",
    "Train the VAE on MNIST or FashionMNIST. Don't forget to save it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bbc2c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bad9c556",
   "metadata": {},
   "source": [
    "**Question 4**\n",
    "\n",
    "With the resulting model:\n",
    " * show some generated samples;\n",
    " * check the quality of the reconstruction;\n",
    " * show some interpolations between images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec17841",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9913d9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9082b156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b4850b0",
   "metadata": {},
   "source": [
    "## Conditional VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0757ecf",
   "metadata": {},
   "source": [
    "**Question 5**\n",
    "\n",
    "Modify the VAE to build a conditional VAE:\n",
    " * the input vectors should be enriched with a one-hot vector coding for the class;\n",
    " * went sent to the decoder, the latent representation should be enriched with a one-hot vector coding for the class.\n",
    "\n",
    "Modify also the function `train_model_vae`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f35d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d37850",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'if' statement on line 20 (2948407004.py, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 22\u001b[0;36m\u001b[0m\n",
      "\u001b[0;31m    else:\u001b[0m\n",
      "\u001b[0m    ^\u001b[0m\n",
      "\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 20\n"
     ]
    }
   ],
   "source": [
    "def train_model_vae(data_loader, model, criterion, optimizer, nepochs, cond = False):\n",
    "    #List to store loss to visualize\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    start_epoch = 0\n",
    "\n",
    "    for epoch in range(start_epoch, nepochs):\n",
    "        train_loss = 0.\n",
    "        valid_loss = 0.\n",
    "        correct = 0\n",
    "\n",
    "        model.train()\n",
    "        for batch_idx, (input_, target) in enumerate(data_loader):\n",
    "            input_ = input_.to(device)\n",
    "            target = target.to(device)\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            if cond:\n",
    "                # ...\n",
    "            else:\n",
    "                # ...\n",
    "\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(input_, output_, mean, logvar)\n",
    "\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "\n",
    "            # update training loss\n",
    "            train_loss += loss.item() * input_.size(0)\n",
    "\n",
    "        # calculate average losses\n",
    "        train_loss = train_loss/len(data_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # print losses statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "            epoch, train_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598221b0",
   "metadata": {},
   "source": [
    "**Question 6**\n",
    "\n",
    "Train the model.\n",
    "\n",
    "With the resulting model:\n",
    " * show some generated samples;\n",
    " * check the quality of the reconstruction;\n",
    " * show some interpolations between images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdc4241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c0294b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b8a1cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3d488a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fd0f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0934990c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c317ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aadafc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "778afc65",
   "metadata": {},
   "source": [
    "# Variational inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3951a921",
   "metadata": {},
   "source": [
    "The goal is to build a variational inference (VI) model. We will use the family of independent Gaussian distributions, which means that each parameter $\\theta_k$ of the model will be randomly generated w.r.t. a Gaussian distribution $\\mathcal{N}(\\mu_k, \\sigma_k^2)$. The parameters to be learned are the $(\\mu_1, \\sigma_1^2, \\cdots, \\mu_p, \\sigma_p^2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7bb15c",
   "metadata": {},
   "source": [
    "To simplify, we will work with a multilayer perceptron. For each pass trhough the model, we will generate randomly the weights and the biases w.r.t. their own Gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c084a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "#mean, std = .2860, .3530\n",
    "\n",
    "# build transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    ]) \n",
    "\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.MNIST(datasets_path, train = True,\n",
    "                              download = True, transform = transform)\n",
    "test_data = datasets.MNIST(datasets_path, train=False,\n",
    "                             download = True, transform = transform)\n",
    "\n",
    "train_size = len(train_data)\n",
    "test_size = len(test_data)\n",
    "\n",
    "# build the data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "# specify the image classes\n",
    "classes = [f\"{i}\" for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d621fc",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "Build a `Module` named `LinearVI` that is similar to the `Linear` layer, but contains the means and variances of the independent Gaussian distributions generating the weights and the biases:\n",
    "* the log-variances will be stored instead the variances themselves;\n",
    "* the means/log-variances should be implemented both for the weights and the biases;\n",
    "* the `forward` method should be implemented: it is recommended to start with generating Gaussian noise, and then translate and scale it to obtain the weights and biases; one can use the function `F.Linear` to compute the output;\n",
    "* the attributes `weight_prior_logvar` and `bias_prior_logvar` contain the initialization log-variance for the weighs and for the biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228a30d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearVI(nn.Module):\n",
    "    def __init__(self, ...):\n",
    "        \n",
    "        ...\n",
    "        \n",
    "        self.weight_prior_logvar = np.log(1 / n_in)\n",
    "        self.bias_prior_logvar = np.log(.01)\n",
    "        \n",
    "        ...\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded9fc39",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "Build a multilayer perceptron `PerceptronVI` made of fully-connected variational layers (`LinearVI`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c43b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronVI(torch.nn.Module):\n",
    "    def __init__(self, ...):\n",
    "        ...\n",
    "\n",
    "    def forward(self, x):\n",
    "        ...\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a38ce36",
   "metadata": {},
   "source": [
    "**Question 3**\n",
    "\n",
    "Complete the train function below. The `loss_kl` is defined as:\n",
    "$$\n",
    "L(\\boldsymbol{\\theta}) = \\lambda \\sum_{k = 1}^p \\left[ \\frac{1}{2} \\log\\left(\\frac{\\sigma_{0k}^2}{\\sigma_k^2}\\right) +\\frac{\\sigma_k^2 + \\mu_k^2}{2 \\sigma_{0k}^2} + \\frac{1}{2}\\right] ,\n",
    "$$\n",
    "where $\\sigma_{0k}^2$ is the variance of the prior distribution on $\\theta_k$ (defined for each layer via `weight_prior_logvar` and `bias_prior_logvar`) and $\\lambda$ is the penalty factor `pen_factor`.\n",
    "\n",
    "It is recommended to add new methods to `LinearVI` and `PerceptronVI`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca522212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_vi(model, criterion, optimizer, nepochs, pen_factor = 1/60000):\n",
    "    #List to store loss to visualize\n",
    "    train_losses = []\n",
    "    train_acc = []\n",
    "    start_epoch = 0\n",
    "\n",
    "    for epoch in range(start_epoch, nepochs):\n",
    "        train_loss = 0.\n",
    "        valid_loss = 0.\n",
    "        correct = 0\n",
    "\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "\n",
    "            # calculate the batch loss\n",
    "            loss_fit = criterion(output, target)\n",
    "            loss_kl = # ... TODO HERE\n",
    "            loss = loss_fit + loss_kl\n",
    "\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "\n",
    "            # update training loss\n",
    "            train_loss += loss.item() * data.size(0)\n",
    "            \n",
    "            # accuracy\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "\n",
    "        # calculate average losses\n",
    "        train_loss = train_loss/len(train_loader.dataset)\n",
    "        accuracy = correct/len(train_loader.dataset)*100\n",
    "        train_acc.append(accuracy)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # print losses statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tTraining accuracy: {:.6f}'.format(\n",
    "            epoch, train_loss, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea178db",
   "metadata": {},
   "source": [
    "**Question 4**\n",
    "\n",
    "Train the model for various $\\lambda$ and plot the posterior distributions obtained for parameters of different layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61d399b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36042453",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
